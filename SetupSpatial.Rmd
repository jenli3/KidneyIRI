---
title: "Spatial setup scripts"
author: "Jen Li"
output: html_document
---

setup.spatial.R
```{r, eval = FALSE}
###############################################################################
#   setwd("~/Documents/Project data - R files/SpatialT/") 
###############################################################################

# Load packages
###############################################################################
###############################################################################
library(BiocParallel)
library(BiocManager)

packagesload = c()
packagesload = c("tidyverse", "dplyr", "readxl", "ggpubr", "graphics", "Gmisc", "knitr", "table1", 
                 "MatchIt", "htmlTable", "magrittr", "survminer", "survival", "lattice", "rstatix", 
                 "viridis", "pROC",  "reshape2", "rcompanion", "edgeR", "limma", "Glimma", "parallel",
                 "AnnotationDbi", "GOexpress", "Matrix", "org.Hs.eg.db", "org.Mm.eg.db", "ggfortify", 
                 "RColorBrewer", "mixOmics", "VennDiagram", "monocle", "Rtsne", "gplots", "ggplot2", 
                 "NMF", "EnhancedVolcano", "calibrate", "pheatmap", "vsn", "Seurat", "SeuratObject", 
                 "patchwork", "PCAtools", "rrcov", "pcaExplorer", "usethis", "devtools", "ComICS",
                 "pathview", "rjson","cowplot", "grid", "readbitmap", "rhdf5", "hdf5r", "data.table", 
                 "tibble", "clusterProfiler", "ReactomePA", "pathview", "enrichplot", "DOSE", 
                 "stringr", "gridExtra", "Rcpp", "NMF", "kableExtra", "imager",  "spdep", "scuttle",
                 "pathfindR", "topGO", "biomaRt", "STdeconvolve", "STutility", "SpatialCPie", "scran",
                 "clustree", "pander", "pagoda2", "harmony", "SingleCellExperiment", "SCINA", 
                 "ggcorrplot", "SpatialExperiment", "TENxVisiumData", "devtools", "FSA", 
                 "superheat", "beachmat",
                 "shiny", "xtable","S4Vectors", "MASS", "Giotto", "Nebulosa","scmap","GEOquery",
                 "singleCellHaystack", "NMF", "gt", "igraph", "GOplot", "ggnewscale", "ggvenn",  
                 "forcats", "stringr", "ggrepel", "readr", "tidyr", "XML", "harmony", "SingleR", 
                 "celldex", "SingleCellExperiment", "SCINA", "shiny", "ggVennDiagram", "directPA")

# Install packages not yet installed, then load
installed_packages = packagesload %in% rownames(installed.packages())
if (any(installed_packages == FALSE)) {
  install.packages(packagesload[!installed_packages], dependencies = TRUE)}
invisible(lapply(packagesload, library, character.only = TRUE))

pkg.versions = data.frame(packagesload)
colnames(pkg.versions) = "packages.used"
pkg.versions$version = "NA"
for (i in 1:length(pkg.versions$packages.used)){
  pkg.versions[i,]$version = package.version(pkg.versions[i,]$packages.used)}

n = 20
qual_col_pals = brewer.pal.info[brewer.pal.info$category == 'qual',]
col_vector = unlist(mapply(brewer.pal, qual_col_pals$maxcolors, rownames(qual_col_pals)))

heatmap.colors = c("lightgray", "mistyrose", "red", "darkred", "black")
###############################################################################
###############################################################################

######### Features for each spot and sample ############
se_features = function(se) {
  se_feat = c()
  se_feat = as.data.frame(levels(as.factor(se@meta.data$sample_id)))
  colnames(se_feat) = "sample"
  
  s1 = 1:length(levels(as.factor(se@meta.data$sample_id)))
  se_descrip = c()
  se_descrip1 = c()
  se_fspot=c()
  se_fnumi=c()
  se_fncount=c()
  se_ffeat=c()
  
  for (i in s1){
    se_descrip[[i]] = levels(as.factor(se@meta.data$treatment[
      se@meta.data$sample_id == (paste0("section_",i,sep=""))]))
    se_descrip1[[i]] = eval(parse(text = paste0("se_descrip.",i, sep = "")))
    se_fspot[[i]] = c(nrow(se_descrip1[[i]]@meta.data))
    se_fnumi[[i]] = c(median(se_descrip1[[i]]@meta.data$nCount_RNA))
    se_fncount[[i]] = c(median(se_descrip1[[i]]@meta.data$nCount_SCT))
    se_ffeat[[i]] =c(median(se_descrip1[[i]]@meta.data$nFeature_SCT)) }
  
  se_feat$treatment = unlist(se_descrip)
  se_feat$spots=unlist(se_fspot)
  se_feat$uMI=unlist(se_fnumi)
  se_feat$nCount=unlist(se_fncount)
  se_feat$nFeature=unlist(se_ffeat)
  return(se_feat)}

############ Number of spots per cluster ###################
clustspots = function(se) {
  clust_feat = c()
  clust_feat = as.data.frame(levels(se@meta.data$seurat_clusters))
  colnames(clust_feat) = "clusters"
  
  spot1 = c()
  # for overall
  t1 = 1: nrow(clust_feat)
  for (i in t1){
    spot1[[i]] = length(which(se@meta.data$seurat_clusters==(i-1))==TRUE) }
  
  clust_feat$all = unlist(spot1)
  
  # now adding new column per sample
  samp=c()
  spot2=c()
  store =c()
  rename = c()
  t2 = 1: length(levels(as.factor(se@meta.data$slide)))
  for (j in t2) {
    samp[[j]] = levels(as.factor(se@meta.data$slide))[j]
    for (i in t1){
      spot2[[i]] = length(which(se@meta.data$seurat_clusters==(i-1) & se@meta.data$slide == samp[[j]])==TRUE)}
    rename = c(names(clust_feat), samp[[j]])
    clust_feat = cbind(clust_feat, unlist(spot2))
    names(clust_feat) = rename}
  return(clust_feat)}

############ stats for each clust vs rest of tissue ##############
clustvsrest = function(se, threshold){
  se.markers = c()
  se.markers = FindAllMarkers(se, only.pos = FALSE, min.pct = 0.05, test.use = "wilcox",
                              logfc.threshold = threshold, seed.use = 42)
  
  se.markers.up = c()
  se.markers.up = se.markers[which(se.markers$avg_log2FC>0), ]
  
  se.markers.down = c()
  se.markers.down = se.markers[which(se.markers$avg_log2FC<0), ]
  
  top5 = se.markers.up %>% group_by(cluster) %>% top_n(n = 5, wt = avg_log2FC) 
  top10 =se.markers.up %>% group_by(cluster) %>% top_n(n = 10, wt = avg_log2FC)
  top20 =se.markers.up %>% group_by(cluster) %>% top_n(n = 20, wt = avg_log2FC)
  
  se.up1 = ElbowPlot(se)
  se.up2 = VizDimLoadings(se, dims = 1:2, reduction = "pca")
  se.up3 =DimPlot(se, reduction = "tsne", split.by = "treatment", ncol = 3, 
                  label = TRUE) +theme_pubr(legend = "right") 
  se.up4 =DimPlot(se, reduction = "umap", split.by = "treatment", ncol = 3, 
                  label = TRUE) +theme_pubr(legend = "right") 
  
  plotup1= ggarrange(se.up1, se.up2, common.legend = TRUE, legend = "right",ncol = 2, nrow = 1)
  plotup2= ggarrange(se.up3, se.up4, common.legend = TRUE, legend = "right",ncol = 2, nrow = 1)
  
  # Cluster vs rest tissue (UP)
  clust_restup = c()
  clust_restup = as.data.frame(levels(se.markers.up$cluster))
  colnames(clust_restup) = "clust vs rest (up)"
  
  up = c()
  top10gene=c()
  t3=c()
  t3 = 1: nrow(clust_restup)
  for (i in t3){
    up[[i]] = length(which(se.markers.up$cluster==(i-1))==TRUE)
    top10gene[[i]] = paste0(unlist(top10$gene[which(top10$cluster==(i-1))]), sep="") }
  
  clust_restup$up = unlist(up)
  clust_restup$top10 = top10gene
  
  setClass("clustrestup", 
           slots = c(clustvsrestup = "data.frame", compstat = "data.frame"), 
           prototype = list(clustvsrestup = data.frame(), compstat = data.frame()))
  
  clust.restup = new("clustrestup",
                     clustvsrestup = se.markers.up,
                     compstat = clust_restup)
  
  # Cluster vs rest tissue (DOWN)
  clust_restdown = c()
  clust_restdown = as.data.frame(levels(se.markers.down$cluster))
  colnames(clust_restdown) = "clust vs rest (down)"
  down = c()
  top10gene=c()
  top10 =c()
  top10 = se.markers.down %>% group_by(cluster) %>% top_n(n = 10, wt = abs(avg_log2FC))
  t3=c()
  t3 = 1: nrow(clust_restdown)
  for (i in t3){
    down[[i]] = length(which(se.markers.down$cluster==(i-1))==TRUE)
    top10gene[[i]] = paste0(unlist(top10$gene[which(top10$cluster==(i-1))]), sep="")
  }
  
  clust_restdown$down = unlist(down)
  clust_restdown$top10 = top10gene
  
  setClass("clustrestdown", 
           slots = c(clustvsrestdown = "data.frame", compstat = "data.frame"), 
           prototype = list(clustvsrestdown = data.frame(), compstat = data.frame()))
  
  clust.restdown = new("clustrestdown",
                       clustvsrestdown = se.markers.down,
                       compstat = clust_restdown)
  
  clustvsrestlist = list(se.markers, se.markers.up, se.markers.down, plotup1, plotup2, clust.restup, clust.restdown)
  
  return(clustvsrestlist)
}

############# Cluster at the full set of resolutions ################
clustpack = function(se) {
  se = RunPCA(se, assay = "SCT", verbose = FALSE, seed.use = 42)
  se = FindNeighbors(se, reduction = "pca", dims = 1:10, seed.use = 42) #SNN
  se = FindClusters(se, verbose = FALSE, resolution = c(0.1, 0.2, 0.3, 0.4, 0.6, 0.8, 1, 1.2), seed.use = 42) 
  se = RunTSNE(se, reduction = "pca", dims =1:10, seed.use = 42)
  se = RunUMAP(se, reduction = "pca", dims = 1:10, seed.use = 42) # optimise
  # se = RunUMAP(object = se, dims = 1:40, verbose = FALSE, n.components = 6, 
  #               reduction = "pca", reduction.name="umap.3d")
  return(se)
}

################ Cluster at specific resolution ##################
clustpackres = function(se, resolution) {
  se = RunPCA(se, assay = "SCT", verbose = FALSE, seed.use = 42)
  se = FindNeighbors(se, reduction = "pca", dims = 1:10, seed.use = 42) #SNN
  se = FindClusters(se, verbose = FALSE, resolution = c(resolution), seed.use = 42) 
  se = RunTSNE(se, reduction = "pca", dims =1:10, seed.use = 42)
  se = RunUMAP(se, reduction = "pca", dims = 1:10, seed.use = 42) # optimise
  # se = RunUMAP(object = se, dims = 1:40, verbose = FALSE, n.components = 6, 
  #               reduction = "pca", reduction.name="umap.3d")
  return(se)
}

############# CLUSTERING RESOLUTION - optimise for low res ##############
clustresolve = function(se){
  se.2=c()
  se.2 = FindClusters(se, resolution = 0, random.seed = 42)
  se.2 = FindClusters(se.2, resolution = 0.1, random.seed = 42)
  se.2 = FindClusters(se.2, resolution = 0.2, random.seed = 42)
  se.2 = FindClusters(se.2, resolution = 0.3, random.seed = 42)
  se.2 = FindClusters(se.2, resolution = 0.4, random.seed = 42)
  se.2 = FindClusters(se.2, resolution = 0.6, random.seed = 42)
  se.2 = FindClusters(se.2, resolution = 0.8, random.seed = 42)
  se.2 = FindClusters(se.2, resolution = 1, random.seed = 42)
  se.2 = FindClusters(se.2, resolution = 1.2, random.seed = 42)
  se.2 = FindClusters(se.2, resolution = 1.4, random.seed = 42)
  se.2 = FindClusters(se.2, resolution = 1.6, random.seed = 42)
  
  se.2 = RunUMAP(se.2, reduction = "pca", dims = 1:10)
  
  s0 = DimPlot(se.2, reduction = "umap", group.by = "SCT_snn_res.0") + ggtitle("res = 0")
  s0.1 = DimPlot(se.2, reduction = "umap", group.by = "SCT_snn_res.0.1") + ggtitle("res = 0.1")
  s0.2 = DimPlot(se.2, reduction = "umap", group.by =  "SCT_snn_res.0.2") + ggtitle("res = 0.2")
  s0.3 = DimPlot(se.2, reduction = "umap", group.by =  "SCT_snn_res.0.3") + ggtitle("res = 0.3")
  s0.4 = DimPlot(se.2, reduction = "umap", group.by = "SCT_snn_res.0.4") + ggtitle("res = 0.4")
  s0.6 = DimPlot(se.2, reduction = "umap", group.by = "SCT_snn_res.0.6") + ggtitle("res = 0.6")
  s0.8 = DimPlot(se.2, reduction = "umap", group.by = "SCT_snn_res.0.8") + ggtitle("res = 0.8")
  s1 = DimPlot(se.2, reduction = "umap", group.by = "SCT_snn_res.1") + ggtitle("res = 1")
  s1.2 = DimPlot(se.2, reduction = "umap", group.by =  "SCT_snn_res.1.2") + ggtitle("res = 1.2")
  s1.4 = DimPlot(se.2, reduction = "umap", group.by =  "SCT_snn_res.1.4") + ggtitle("res = 1.4")
  s1.6 = DimPlot(se.2, reduction = "umap", group.by = "SCT_snn_res.1.6") + ggtitle("res = 1.6")
  
  # # Multi plot for a selection
  (s0.2 + s0.4+ s0.6)/ (s0.8+s1 + s1.2)
  
  clust_se = c()
  clust_se = clustree(se.2, prefix = "SCT_snn_res.", layout = "tree",
                      node_colour = "sc3_stability", node_text_colour = "white",
                      edge_width = 1, node_label_size = 5, edge_arrow = FALSE)
  c1=clust_se
  
  # # highest avg sc3_stabaility score ~ which of the possible clustering resolutions is the most stable 
  stability_se = c()
  stability_se = clust_se$data[,c("SCT_snn_res.", "sc3_stability")]
  stability_se = stability_se[stability_se$SCT_snn_res. %in%
                                names(which(table(stability_se$SCT_snn_res.) > 1)), ]
  
  stability_se.summary = c()
  stability_se.summary = as.data.frame(stability_se %>%
                                         group_by(SCT_snn_res.) %>%
                                         summarize(mean = mean(sc3_stability),
                                                   median = median(sc3_stability),
                                                   sd = sd(sc3_stability),
                                                   min = min(sc3_stability),
                                                   max = max(sc3_stability),
                                                   cv = sd(sc3_stability)/mean(sc3_stability)))
  
  rownames(stability_se.summary) = stability_se.summary$SCT_snn_res.
  stability_se.summary$SCT_snn_res. = NULL
  
  # 
  bestres_se_mean = c()
  bestres_se_med = c()
  bestres_se_lowCV = c()
  bestres_se_mean = rownames(stability_se.summary)[which.max(stability_se.summary$mean)]
  bestres_se_med = rownames(stability_se.summary)[which.max(stability_se.summary$median)]
  bestres_se_lowCV = rownames(stability_se.summary)[which.min(stability_se.summary$cv)]
  
  s1= emphasize.strong.rows(which.max(stability_se.summary$mean))
  
  p1= pander(stability_se.summary, split.cells = 5, split.table = Inf,
             caption = 'Spot per section', label = '10', digits = 2,justify ='center')
  
  # # Optimal resolution is subjective: combine biological info and stats (higher median and lower spread of data - so check median for central tendency for the non-normally distributed data)
  stability_se %>% ggplot(aes(SCT_snn_res., sc3_stability)) + geom_boxplot()+ ggtitle("Batch") +scale_y_continuous(trans='log2')+theme_pubclean()
  
  # and simplistic check to elbow plot
  e1= ElbowPlot(se)
  
  listse2 = list(se.2, p1, e1, s1, c1)
  return(listse2)
}


# ENRICHMENTS
############## pre-process the clust vs rest #######################
#  (target = cluster of interest, data1 = dataframe se.clust etc)
clustall = function(data1, target1) {
  clust = c()
  clust = data1[data1$cluster==target1,]
  clust$symbol = clust$gene
  clust$ensembl = gene.conversions$ensembl[match(clust$gene, gene.conversions$symbol)]
  # # clust$rank = clust$avg_log2FC * (-log10(clust$p_val_adj))
  # # clust$rank = ifelse(clust$rank == "Inf", 10^6, clust$rank)
  # clust = clust[order(-clust$avg_log2FC),]
  # clust = clust[!duplicated(clust$gene),]
  # if (nrow(clust) < 500) {
  #   entz=c()
  #   entz = mapIds(org.Mm.eg.db, keys=clust$ensembl, column="ENTREZID", keytype="ENSEMBL", multiVals="first")
  #   clust = cbind(clust, ENTREZID = entz)
  #   } else {
  #     entz=c()
  #     entz = bitr(clust$ensembl, fromType = "ENSEMBL", toType ="ENTREZID", OrgDb = org.Mm.eg.db, drop = FALSE)
  #     entz = entz[!duplicated(entz$ENSEMBL),]
  #     clust$ENTREZID = entz$ENTREZID
  #     }
  return(clust)
}

clustall1 = function(data1, target1) {
  clust = c()
  clust = data1[data1$cluster==target1,]
  clust$symbol = clust$gene
  clust$ensembl = gene.conversions$ensembl[match(clust$gene, gene.conversions$symbol)]
  # clust$rank = clust$avg_log2FC * (-log10(clust$p_val_adj))
  # clust$rank = ifelse(clust$rank == "Inf", 10^6, clust$rank)
  clust = clust[order(-clust$avg_log2FC),]
  clust = clust[!duplicated(clust$gene),]
  if (nrow(clust) < 500) {
    entz=c()
    entz = mapIds(org.Mm.eg.db, keys=clust$ensembl, column="ENTREZID", keytype="ENSEMBL", multiVals="first")
    clust = cbind(clust, ENTREZID = entz)
  } else {
    
    clust$ENTREZID = NA
  }
  return(clust)
}

############ Cluster vs rest (DGE - UP) ################
clustrestup = function(data1, target1) {
  clust = c()
  clust = data1@clustvsrestup[data1@clustvsrestup$cluster==target1,]
  clust$symbol = clust$gene
  clust$ensembl = gene.conversions$ensembl[match(clust$gene, gene.conversions$symbol)]
  # clust$rank = clust$avg_log2FC * (-log10(clust$p_val_adj))
  # clust$rank = ifelse(clust$rank == "Inf", 10^6, clust$rank)
  clust = clust[order(-clust$avg_log2FC),]
  clust = clust[!duplicated(clust$gene),]
  if (nrow(clust) < 500) {
    entz=c()
    entz = mapIds(org.Mm.eg.db, keys=clust$ensembl, column="ENTREZID", keytype="ENSEMBL", multiVals="first")
    clust = cbind(clust, ENTREZID = entz)
  } else {
    entz=c()
    entz = bitr(clust$ensembl, fromType = "ENSEMBL", toType ="ENTREZID", OrgDb = org.Mm.eg.db, drop = FALSE)
    entz = entz[!duplicated(entz$ENSEMBL),]
    clust$ENTREZID = entz$ENTREZID
  }
  return(clust)
}


clustrestup1 = function(data1, target1) {
  clust = c()
  clust = data1[data1$cluster==target1,]
  clust$symbol = clust$gene
  clust$ensembl = gene.conversions$ensembl[match(clust$gene, gene.conversions$symbol)]
  # clust$rank = clust$avg_log2FC * (-log10(clust$p_val_adj))
  # clust$rank = ifelse(clust$rank == "Inf", 10^6, clust$rank)
  clust = clust[order(-clust$avg_log2FC),]
  clust = clust[!duplicated(clust$gene),]
  if (nrow(clust) < 500) {
    entz=c()
    entz = mapIds(org.Mm.eg.db, keys=clust$ensembl, column="ENTREZID", keytype="ENSEMBL", multiVals="first")
    clust = cbind(clust, ENTREZID = entz)
  } else {
    entz=c()
    entz = bitr(clust$ensembl, fromType = "ENSEMBL", toType ="ENTREZID", OrgDb = org.Mm.eg.db, drop = FALSE)
    entz = entz[!duplicated(entz$ENSEMBL),]
    clust$ENTREZID = entz$ENTREZID
  }
  return(clust)
}

############ Cluster vs rest (DGE - DOWN) ################
clustrestdown = function(data1, target1) {
  clust = c()
  clust = data1@clustvsrestdown[data1@clustvsrestdown$cluster==target1,]
  clust$symbol = clust$gene
  clust$ensembl = gene.conversions$ensembl[match(clust$gene, gene.conversions$symbol)]
  # clust$rank = clust$avg_log2FC * (-log10(clust$p_val_adj))
  #   clust$rank = ifelse(clust$rank == "Inf", 10^6, clust$rank)
  clust = clust[order(-clust$avg_log2FC),]
  clust = clust[!duplicated(clust$gene),]
  if (nrow(clust) < 500) {
    entz=c()
    entz = mapIds(org.Mm.eg.db, keys=clust$ensembl, column="ENTREZID", keytype="ENSEMBL", multiVals="first")
    clust = cbind(clust, ENTREZID = entz)
  } else {
    entz=c()
    entz = bitr(clust$ensembl, fromType = "ENSEMBL", toType ="ENTREZID", OrgDb = org.Mm.eg.db, drop = FALSE)
    entz = entz[!duplicated(entz$ENSEMBL),]
    clust$ENTREZID = entz$ENTREZID
  }
  return(clust)
}

clustrestdown1 = function(data1, target1) {
  clust = c()
  clust = data1[data1$cluster==target1,]
  clust$symbol = clust$gene
  clust$ensembl = gene.conversions$ensembl[match(clust$gene, gene.conversions$symbol)]
  # clust$rank = clust$avg_log2FC * (-log10(clust$p_val_adj))
  # clust$rank = ifelse(clust$rank == "Inf", 10^6, clust$rank)
  clust = clust[order(-clust$avg_log2FC),]
  clust = clust[!duplicated(clust$gene),]
  if (nrow(clust) < 500) {
    entz=c()
    entz = mapIds(org.Mm.eg.db, keys=clust$ensembl, column="ENTREZID", keytype="ENSEMBL", multiVals="first")
    clust = cbind(clust, ENTREZID = entz)
  } else {
    entz=c()
    entz = bitr(clust$ensembl, fromType = "ENSEMBL", toType ="ENTREZID", OrgDb = org.Mm.eg.db, drop = FALSE)
    entz = entz[!duplicated(entz$ENSEMBL),]
    clust$ENTREZID = entz$ENTREZID
  }
  return(clust)
}


######## Pairwise cluster - pre-process (data 1 and target 1 = same number) ############
clustpwup = function(data1, target1, target2) {
  clust.pair = c()
  clust.pair = slot(data1, paste0("comp", target1, "vs", target2, sep  = ""))
  clust.pair = clust.pair[(clust.pair$avg_log2FC > 0),] # up (change to < 0 if down)
  clust.pair$gene = rownames(clust.pair)
  clust.pair$symbol = clust.pair$gene
  clust.pair$ensembl =  gene.conversions$ensembl[match(clust.pair$gene, gene.conversions$symbol)]
  # clust.pair$rank = clust.pair$avg_log2FC * (-log10(clust.pair$p_val_adj))
  # clust.pair$rank = ifelse(clust.pair$rank == "Inf", 10^6, clust.pair$rank)
  clust.pair = clust.pair[order(-clust.pair$avg_log2FC),]
  clust.pair = clust.pair[!duplicated(clust.pair$gene),]
  if (nrow(clust.pair) < 600) {
    entz=c()
    entz = mapIds(org.Mm.eg.db, keys=clust.pair$ensembl, column="ENTREZID", keytype="ENSEMBL", multiVals="first")
    clust.pair = cbind(clust.pair, ENTREZID = entz)
  } else {
    entz=c()
    entz = bitr(clust.pair$ensembl, fromType = "ENSEMBL", toType ="ENTREZID", OrgDb = org.Mm.eg.db, drop = FALSE)
    entz = entz[!duplicated(entz$ENSEMBL),]
    clust.pair$ENTREZID = entz$ENTREZID}
  return(clust.pair)
}


clustpwall = function(data1, target1, target2) {
  clust.pair = c()
  clust.pair = slot(data1, paste0("comp", target1, "vs", target2, sep  = ""))
  clust.pair$gene = rownames(clust.pair)
  clust.pair$symbol = clust.pair$gene
  clust.pair$ensembl =  gene.conversions$ensembl[match(clust.pair$gene, gene.conversions$symbol)]
  # clust.pair$rank = clust.pair$avg_log2FC * (-log10(clust.pair$p_val_adj))
  # clust.pair$rank = ifelse(clust.pair$rank == "Inf", 10^6, clust.pair$rank)
  clust.pair = clust.pair[order(-clust.pair$avg_log2FC),]
  clust.pair = clust.pair[!duplicated(clust.pair$gene),]
  if (nrow(clust.pair) < 600) {
    entz=c()
    entz = mapIds(org.Mm.eg.db, keys=clust.pair$ensembl, column="ENTREZID", keytype="ENSEMBL", multiVals="first")
    clust.pair = cbind(clust.pair, ENTREZID = entz)
  } else {
    entz=c()
    entz = bitr(clust.pair$ensembl, fromType = "ENSEMBL", toType ="ENTREZID", OrgDb = org.Mm.eg.db, drop = FALSE)
    entz = entz[!duplicated(entz$ENSEMBL),]
    clust.pair$ENTREZID = entz$ENTREZID}
  return(clust.pair)
}

clustpprocess = function(data1) {
  clust.pair = c()
  clust.pair = data1
  clust.pair$gene = rownames(clust.pair)
  clust.pair$symbol = clust.pair$gene
  clust.pair$ensembl =  gene.conversions$ensembl[match(clust.pair$gene,
                                                       gene.conversions$symbol)]
  # clust.pair$rank = clust.pair$avg_log2FC * (-log10(clust.pair$p_val_adj))
  # clust.pair$rank = ifelse(clust.pair$rank == "Inf", 10^6, clust.pair$rank)
  # clust.pair = clust.pair[order(-clust.pair$avg_log2FC),]
  # clust.pair = clust.pair[!duplicated(clust.pair$gene),]
  #     entz=c()
  #     entz = bitr(clust.pair$ensembl, fromType = "ENSEMBL", 
  #                  toType ="ENTREZID", OrgDb = org.Mm.eg.db, drop = FALSE)
  #     entz = entz[!duplicated(entz$ENSEMBL),]
  #     clust.pair$ENTREZID = entz$ENTREZID
  
  clust.pair$diffexpressed = "NO"
  clust.pair$diffexpressed[clust.pair$avg_log2FC > 0 & clust.pair$p_val_adj < 0.05] = "UP"
  clust.pair$diffexpressed[clust.pair$avg_log2FC < 0 & clust.pair$p_val_adj < 0.05] = "DOWN"
  clust.pair$dlabel = NA
  clust.pair$dlabel[clust.pair$diffexpressed != "NO"] =
    clust.pair$symbol[clust.pair$diffexpressed != "NO"]
  return(clust.pair)
}

##### Z scores ########
cal_z_score = function(x){(x - mean(x)) / sd(x)}

###### remove processess not relevant to our research from final list #######
removecrap = function(data){
  remove1 = c(data$Description[grep("ameboidal", data$Description, ignore.case = TRUE)], 
              data$Description[grep("glial", data$Description, ignore.case = TRUE)], 
              data$Description[grep("spine", data$Description, ignore.case = TRUE)], 
              data$Description[grep("rhythmic", data$Description, ignore.case = TRUE)], 
              data$Description[grep("heart", data$Description, ignore.case = TRUE)], 
              data$Description[grep("hair", data$Description, ignore.case = TRUE)],
              data$Description[grep("cardiac", data$Description, ignore.case = TRUE)], 
              data$Description[grep("aorta", data$Description, ignore.case = TRUE)], 
              data$Description[grep("valve", data$Description, ignore.case = TRUE)], 
              data$Description[grep("covid", data$Description, ignore.case = TRUE)], 
              data$Description[grep("embryo", data$Description, ignore.case = TRUE)], 
              data$Description[grep("biotic", data$Description, ignore.case = TRUE)], 
              data$Description[grep("neuromuscular", data$Description, ignore.case = TRUE)], 
              data$Description[grep("spramolecular", data$Description, ignore.case = TRUE)], 
              data$Description[grep("clathrin", data$Description, ignore.case = TRUE)], 
              data$Description[grep("bone", data$Description, ignore.case = TRUE)], 
              data$Description[grep("endocondral", data$Description, ignore.case = TRUE)], 
              data$Description[grep("ER", data$Description, ignore.case = TRUE)], 
              data$Description[grep("melanocyte", data$Description, ignore.case = TRUE)], 
              data$Description[grep("collagen", data$Description, ignore.case = TRUE)], 
              data$Description[grep("tube", data$Description, ignore.case = TRUE)], 
              data$Description[grep("coronary", data$Description, ignore.case = TRUE)], 
              data$Description[grep("vascular", data$Description, ignore.case = TRUE)], 
              data$Description[grep("visual", data$Description, ignore.case = TRUE)], 
              data$Description[grep("disc", data$Description, ignore.case = TRUE)], 
              data$Description[grep("synaptic", data$Description, ignore.case = TRUE)], 
              data$Description[grep("tree", data$Description, ignore.case = TRUE)], 
              data$Description[grep("somatodendritic", data$Description, ignore.case = TRUE)], 
              data$Description[grep("detection", data$Description, ignore.case = TRUE)], 
              data$Description[grep("sensory", data$Description, ignore.case = TRUE)], 
              data$Description[grep("virus", data$Description, ignore.case = TRUE)], 
              data$Description[grep("neuron", data$Description, ignore.case = TRUE)], 
              data$Description[grep("viral", data$Description, ignore.case = TRUE)], 
              data$Description[grep("gonad", data$Description, ignore.case = TRUE)], 
              data$Description[grep("biological", data$Description, ignore.case = TRUE)], 
              data$Description[grep("organ", data$Description, ignore.case = TRUE)], 
              data$Description[grep("male", data$Description, ignore.case = TRUE)], 
              data$Description[grep("female", data$Description, ignore.case = TRUE)], 
              data$Description[grep("syncitium", data$Description, ignore.case = TRUE)], 
              data$Description[grep("ossification", data$Description, ignore.case = TRUE)], 
              data$Description[grep("reproductive", data$Description, ignore.case = TRUE)], 
              data$Description[grep("symbiotic", data$Description, ignore.case = TRUE)], 
              data$Description[grep("alcohol", data$Description, ignore.case = TRUE)], 
              data$Description[grep("actin", data$Description, ignore.case = TRUE)], 
              data$Description[grep("synapse", data$Description, ignore.case = TRUE)], 
              data$Description[grep("muscle", data$Description, ignore.case = TRUE)], 
              data$Description[grep("gliogenesis", data$Description, ignore.case = TRUE)],
              data$Description[grep("neuron", data$Description, ignore.case = TRUE)],
              data$Description[grep("neural", data$Description, ignore.case = TRUE)],
              data$Description[grep("striated", data$Description, ignore.case = TRUE)],
              data$Description[grep("artery", data$Description, ignore.case = TRUE)],
              data$Description[grep("biotic", data$Description, ignore.case = TRUE)],
              data$Description[grep("cartilage", data$Description, ignore.case = TRUE)],
              data$Description[grep("vessel", data$Description, ignore.case = TRUE)],
              data$Description[grep("organic", data$Description, ignore.case = TRUE)], 
              data$Description[grep("lithium", data$Description, ignore.case = TRUE)], 
              data$Description[grep("progesterone", data$Description, ignore.case = TRUE)],
              data$Description[grep("spindle", data$Description, ignore.case = TRUE)],
              data$Description[grep("multicellular", data$Description, ignore.case = TRUE)],
              data$Description[grep("myoblast", data$Description, ignore.case = TRUE)],
              data$Description[grep("skeletal", data$Description, ignore.case = TRUE)],
              data$Description[grep("wound", data$Description, ignore.case = TRUE)],
              data$Description[grep("parkinson", data$Description, ignore.case = TRUE)],
              data$Description[grep("cytoskeleton", data$Description, ignore.case = TRUE)])
  
  data = data[!data$Description %in% remove1,]
  return(data)
}

##### Check immune modules ###########3
pickimmune = function(data){
  immune1 = c(data$Description[grep("immune", data$Description, ignore.case = TRUE)], 
              data$Description[grep("lymphocyte", data$Description, ignore.case = TRUE)], 
              data$Description[grep("leukocyte", data$Description, ignore.case = TRUE)], 
              data$Description[grep("B cell", data$Description, ignore.case = TRUE)], 
              data$Description[grep("T cell", data$Description, ignore.case = TRUE)], 
              data$Description[grep("inflammatory", data$Description, ignore.case = TRUE)], 
              data$Description[grep("monocyte", data$Description, ignore.case = TRUE)], 
              data$Description[grep("macrophage", data$Description, ignore.case = TRUE)], 
              data$Description[grep("dendritic", data$Description, ignore.case = TRUE)], 
              data$Description[grep("myeloid", data$Description, ignore.case = TRUE)], 
              data$Description[grep("apc", data$Description, ignore.case = TRUE)], 
              data$Description[grep("nk", data$Description, ignore.case = TRUE)], 
              data$Description[grep("neutrophil", data$Description, ignore.case = TRUE)], 
              data$Description[grep("innate", data$Description, ignore.case = TRUE)], 
              data$Description[grep("adaptive", data$Description, ignore.case = TRUE)], 
              data$Description[grep("platelet", data$Description, ignore.case = TRUE)],
              data$Description[grep("complement", data$Description, ignore.case = TRUE)],
              data$Description[grep("toll", data$Description, ignore.case = TRUE)],
              data$Description[grep("mhc", data$Description, ignore.case = TRUE)],
              data$Description[grep("antigen", data$Description, ignore.case = TRUE)],
              data$Description[grep("chemotaxis", data$Description, ignore.case = TRUE)],
              data$Description[grep("migration", data$Description, ignore.case = TRUE)],
              data$Description[grep("death", data$Description, ignore.case = TRUE)], 
              data$Description[grep("apoptosis", data$Description, ignore.case = TRUE)], 
              data$Description[grep("apoptotic", data$Description, ignore.case = TRUE)], 
              data$Description[grep("immune", data$Description, ignore.case = TRUE)],
              data$Description[grep("pyroptosis", data$Description, ignore.case = TRUE)],
              data$Description[grep("necroptosis", data$Description, ignore.case = TRUE)],
              data$Description[grep("necrosis", data$Description, ignore.case = TRUE)],
              data$Description[grep("autophagy", data$Description, ignore.case = TRUE)],
              data$Description[grep("ferroptosis", data$Description, ignore.case = TRUE)])
  
  data = data[data$Description %in% immune1,]
  return(data)
}

####### Check biologically relevant modules #########
pickrelevant = function(data){
  immune1 = c(data$Description[grep("immune", data$Description, ignore.case = TRUE)], 
              data$Description[grep("lymphocyte", data$Description, ignore.case = TRUE)], 
              data$Description[grep("leukocyte", data$Description, ignore.case = TRUE)], 
              data$Description[grep("lymphoid", data$Description, ignore.case = TRUE)], 
              data$Description[grep("B cell", data$Description, ignore.case = TRUE)], 
              data$Description[grep("T cell", data$Description, ignore.case = TRUE)], 
              data$Description[grep("inflammatory", data$Description, ignore.case = TRUE)], 
              data$Description[grep("monocyte", data$Description, ignore.case = TRUE)], 
              data$Description[grep("macrophage", data$Description, ignore.case = TRUE)], 
              data$Description[grep("dendritic", data$Description, ignore.case = TRUE)], 
              data$Description[grep("myeloid", data$Description, ignore.case = TRUE)], 
              data$Description[grep("apc", data$Description, ignore.case = TRUE)], 
              data$Description[grep("nk", data$Description, ignore.case = TRUE)], 
              data$Description[grep("neutrophil", data$Description, ignore.case = TRUE)], 
              data$Description[grep("innate", data$Description, ignore.case = TRUE)], 
              data$Description[grep("adaptive", data$Description, ignore.case = TRUE)], 
              data$Description[grep("platelet", data$Description, ignore.case = TRUE)],
              data$Description[grep("complement", data$Description, ignore.case = TRUE)],
              data$Description[grep("toll", data$Description, ignore.case = TRUE)],
              data$Description[grep("mhc", data$Description, ignore.case = TRUE)],
              data$Description[grep("antigen", data$Description, ignore.case = TRUE)],
              data$Description[grep("chemotaxis", data$Description, ignore.case = TRUE)],
              data$Description[grep("caspase", data$Description, ignore.case = TRUE)], 
              data$Description[grep("NLRP3", data$Description, ignore.case = TRUE)], 
              data$Description[grep("inflammasome", data$Description, ignore.case = TRUE)], 
              data$Description[grep("aim2", data$Description, ignore.case = TRUE)], 
              data$Description[grep("antigen", data$Description, ignore.case = TRUE)], 
              data$Description[grep("repair", data$Description, ignore.case = TRUE)], 
              data$Description[grep("migration", data$Description, ignore.case = TRUE)],
              data$Description[grep("death", data$Description, ignore.case = TRUE)], 
              data$Description[grep("apoptosis", data$Description, ignore.case = TRUE)], 
              data$Description[grep("apoptotitc", data$Description, ignore.case = TRUE)], 
              data$Description[grep("immune", data$Description, ignore.case = TRUE)],
              data$Description[grep("pyroptosis", data$Description, ignore.case = TRUE)],
              data$Description[grep("necroptosis", data$Description, ignore.case = TRUE)],
              data$Description[grep("necrosis", data$Description, ignore.case = TRUE)],
              data$Description[grep("autophagy", data$Description, ignore.case = TRUE)],
              data$Description[grep("mitochondria", data$Description, ignore.case = TRUE)],
              data$Description[grep("mitochondrial", data$Description, ignore.case = TRUE)],
              data$Description[grep("oxidative", data$Description, ignore.case = TRUE)],
              data$Description[grep("oxidation", data$Description, ignore.case = TRUE)],
              data$Description[grep("fatty acid", data$Description, ignore.case = TRUE)],
              data$Description[grep("lipid", data$Description, ignore.case = TRUE)],
              data$Description[grep("peroxisomes", data$Description, ignore.case = TRUE)], 
              data$Description[grep("leukocyte", data$Description, ignore.case = TRUE)], 
              data$Description[grep("glutathione", data$Description, ignore.case = TRUE)], 
              data$Description[grep("ferroptosis", data$Description, ignore.case = TRUE)],
              data$Description[grep("cycle", data$Description, ignore.case = TRUE)], 
              data$Description[grep("adhesion", data$Description, ignore.case = TRUE)],  
              data$Description[grep("polarity", data$Description, ignore.case = TRUE)],  
              data$Description[grep("mitotic", data$Description, ignore.case = TRUE)],  
              data$Description[grep("epithelial", data$Description, ignore.case = TRUE)],
              data$Description[grep("fibroblast", data$Description, ignore.case = TRUE)], 
              data$Description[grep("exocytosis", data$Description, ignore.case = TRUE)], 
              data$Description[grep("arachadonic", data$Description, ignore.case = TRUE)],
              data$Description[grep("electron", data$Description, ignore.case = TRUE)], 
              data$Description[grep("locomotion", data$Description, ignore.case = TRUE)], 
              data$Description[grep("respiration", data$Description, ignore.case = TRUE)], 
              data$Description[grep("angiogenesis", data$Description, ignore.case = TRUE)],
              data$Description[grep("reduction", data$Description, ignore.case = TRUE)], 
              data$Description[grep("oxygen", data$Description, ignore.case = TRUE)], 
              data$Description[grep("plasma membrane", data$Description, ignore.case = TRUE)], 
              data$Description[grep("NADH", data$Description, ignore.case = TRUE)], 
              data$Description[grep("dehydrogenase", data$Description, ignore.case = TRUE)], 
              data$Description[grep("respirasome", data$Description, ignore.case = TRUE)], 
              data$Description[grep("respiratory", data$Description, ignore.case = TRUE)], 
              data$Description[grep("oxidoreductase", data$Description, ignore.case = TRUE)], 
              data$Description[grep("iron", data$Description, ignore.case = TRUE)], 
              data$Description[grep("heme", data$Description, ignore.case = TRUE)], 
              data$Description[grep("NAD", data$Description, ignore.case = TRUE)],
              data$Description[grep("NF", data$Description, ignore.case = TRUE)], 
              data$Description[grep("kappa", data$Description, ignore.case = TRUE)], 
              data$Description[grep("phosphatidylinositol", data$Description, ignore.case = TRUE)])
  
  data = data[data$Description %in% immune1,]
  return(data)
}


########### sort genes in order for symbol #####################
gene0symbol = function(data1) {
  gene0 = c()
  gene0 = data1$avg_log2FC # the Log2FC
  names(gene0) = data1$symbol # genes
  gene0 = sort(gene0, decreasing = TRUE) # sort decreasing order
  gene0 = gene0[!duplicated(names(gene0))]
  return(gene0)}

########### sort genes in order for ensembl ##################
gene0ensembl = function(data1) {
  gene0 = c()
  gene0 = data1$avg_log2FC # the Log2FC
  names(gene0) = data1$ensembl # genes
  gene0 = sort(gene0, decreasing = TRUE) # sort decreasing order
  gene0 = gene0[!duplicated(names(gene0))]
  return(gene0)}

########### sort genes in order for entrezid #####################
gene0entrezid = function(data1) {
  gene0 = c()
  gene0 = data1$avg_log2FC # the Log2FC
  names(gene0) = data1$ENTREZID # genes
  gene0 = sort(gene0, decreasing = TRUE) # sort decreasing order
  gene0 = gene0[!duplicated(names(gene0))]
  return(gene0)}


######## Over representation analysis with GO (clusterprofiler) ###########
egosummary = function (gene0, pcutoff, qcutoff, adjmethod) {
  # Over representation enrichment analysis
  # ontology cytosolic component
  ego.cc = c()
  ego.cc = enrichGO(gene     = names(gene0),
                    OrgDb         = org.Mm.eg.db,
                    keyType       = 'ENTREZID',
                    ont           = "CC",
                    pAdjustMethod = adjmethod,
                    pvalueCutoff  = pcutoff,
                    qvalueCutoff  = qcutoff, 
                    readable      = TRUE)
  egocc = c()
  egocc = filter(ego.cc, p.adjust < 0.05, qvalue < 0.05)
  egocc = mutate(egocc, geneRatio = parse_ratio(GeneRatio)) %>% arrange(desc(geneRatio))
  egocc = mutate(egocc, richFactor = Count / as.numeric(sub("/\\d+", "", BgRatio)))
  egocc = mutate(egocc, FoldEnrichment = parse_ratio(GeneRatio) / parse_ratio(BgRatio))
  
  cc1 = barplot(egocc, showCategory=20, title ="cytosolic component")
  cc2 = dotplot(egocc, showCategory=20, title ="cytosolic component")
  cc3 = upsetplot(egocc)
  cc4 = heatplot(egocc)
  cc5 = goplot(egocc)
  cc6 = ggplot(egocc, showCategory = 20, aes(FoldEnrichment, fct_reorder(Description, FoldEnrichment))) + 
    geom_point(aes(color=p.adjust, size = Count)) +
    scale_color_viridis_c(guide=guide_colorbar(reverse=TRUE)) +
    scale_size_continuous(range=c(2, 10)) +theme_minimal() + xlab("FoldEnrichment") +
    ylab(NULL) + ggtitle("Enriched GO:CC - FE")
  
  listcc = list(cc1, cc2, cc3, cc4, cc5, cc6)
  
  # ontology = molecular function
  ego.mf = c()
  ego.mf = enrichGO(gene   = names(gene0),
                    OrgDb         = org.Mm.eg.db,
                    keyType       = 'ENTREZID',
                    ont           = "MF",
                    pAdjustMethod = adjmethod,
                    pvalueCutoff  = pcutoff,
                    qvalueCutoff  = qcutoff, 
                    readable      = TRUE)
  
  egomf = c()
  egomf = filter(ego.mf, p.adjust < 0.05, qvalue < 0.05)
  egomf = mutate(egomf, geneRatio = parse_ratio(GeneRatio)) %>% arrange(desc(geneRatio))
  egomf = mutate(egomf, richFactor = Count / as.numeric(sub("/\\d+", "", BgRatio)))
  egomf = mutate(egomf, FoldEnrichment = parse_ratio(GeneRatio) / parse_ratio(BgRatio))
  
  mf1 = barplot(egomf, showCategory=20, title ="molecular function")
  mf2 = dotplot(egomf, showCategory=20, title ="molecular function")
  mf3 = upsetplot(egomf)
  mf4 = heatplot(egomf)
  mf5 = goplot(egomf)
  mf6  = ggplot(egomf, showCategory = 20, aes(FoldEnrichment, fct_reorder(Description, FoldEnrichment))) + 
    geom_point(aes(color=p.adjust, size = Count)) +
    scale_color_viridis_c(guide=guide_colorbar(reverse=TRUE)) +
    scale_size_continuous(range=c(2, 10)) +theme_minimal() + xlab("FoldEnrichment") +
    ylab(NULL) + ggtitle("Enriched GO:MF - FE")
  
  listmf = list(mf1, mf2, mf3, mf4, mf5, mf6)
  
  # ontology = biological process
  ego.bp = c()
  ego.bp = enrichGO(gene   = names(gene0),
                    OrgDb         = org.Mm.eg.db,
                    keyType       = 'ENTREZID',
                    ont           = "BP",
                    pAdjustMethod = adjmethod,
                    pvalueCutoff  = pcutoff,
                    qvalueCutoff  = qcutoff, 
                    readable      = TRUE)
  
  egobp = c()
  egobp = filter(ego.bp, p.adjust < 0.05, qvalue < 0.05)
  egobp = mutate(egobp, geneRatio = parse_ratio(GeneRatio)) %>% arrange(desc(geneRatio))
  egobp = mutate(egobp, richFactor = Count / as.numeric(sub("/\\d+", "", BgRatio)))
  egobp = mutate(egobp, FoldEnrichment = parse_ratio(GeneRatio) / parse_ratio(BgRatio))
  
  
  bp1 = barplot(egobp, showCategory=20,  title ="biological process")
  bp2 = dotplot(egobp, showCategory=20,  title ="biological process")
  bp3 = upsetplot(egobp)
  bp4 = heatplot(egobp)
  bp5 = goplot(egobp)
  bp6 = ggplot(egobp, showCategory = 20, 
               aes(FoldEnrichment, fct_reorder(Description, FoldEnrichment))) + 
    geom_point(aes(color=p.adjust, size = Count)) +
    scale_color_viridis_c(guide=guide_colorbar(reverse=TRUE)) +
    scale_size_continuous(range=c(2, 10)) +theme_minimal() + xlab("FoldEnrichment") +
    ylab(NULL) + ggtitle("Enriched GO:BP")
  
  listbp=list(bp1, bp2, bp3, bp4, bp5, bp)
}


####### Over representation analysis with KEGG (clusterprofiler) #############
ekeggsummary = function (gene0, pcutoff, qcutoff, adjmethod) {
  # Enrich for KEGG
  ekegg.mmu = c()
  ekegg.mmu = enrichKEGG(gene  = names(gene0),
                         organism     = 'mmu',
                         pAdjustMethod = adjmethod,
                         pvalueCutoff = pcutoff,
                         qvalueCutoff = qcutoff)
  
  ekegg = c()
  ekegg = filter(ekegg.mmu, p.adjust < 0.05, qvalue < 0.05)
  ekegg = mutate(ekegg, geneRatio = parse_ratio(GeneRatio)) %>% arrange(desc(geneRatio))
  ekegg = mutate(ekegg, richFactor = Count / as.numeric(sub("/\\d+", "", BgRatio)))
  ekegg = mutate(ekegg, FoldEnrichment = parse_ratio(GeneRatio) / parse_ratio(BgRatio))
  
  ek1 = barplot(ekegg, showCategory=20,  title ="KEGG")
  ek2 = dotplot(ekegg, showCategory=20,  title ="KEGG")
  ek3 = upsetplot(ekegg)
  ek4 = heatplot(ekegg)
  ek5 = ggplot(ekegg, showCategory = 20, aes(geneRatio, fct_reorder(Description, geneRatio))) +
    geom_point(aes(color=p.adjust, size = Count))+ #geom_segment(aes(xend=0, yend = Description)) +
    scale_color_viridis_c(guide=guide_colorbar(reverse=TRUE)) +
    scale_size_continuous(range=c(2, 10)) +theme_minimal() +
    xlab("GeneRatio") +ylab(NULL) + ggtitle("Enriched KEGG - GR")
  ek6 = ggplot(ekegg, showCategory = 20, aes(richFactor, fct_reorder(Description, richFactor))) +
    geom_point(aes(color=p.adjust, size = Count)) +
    scale_color_viridis_c(guide=guide_colorbar(reverse=TRUE)) +
    scale_size_continuous(range=c(2, 10)) + theme_minimal() + xlab("RichFactor") +
    ylab(NULL) + ggtitle("Enriched KEGG - RF")
  ek7 = ggplot(ekegg, showCategory = 20, aes(FoldEnrichment, fct_reorder(Description, FoldEnrichment))) +
    geom_point(aes(color=p.adjust, size = Count)) +
    scale_color_viridis_c(guide=guide_colorbar(reverse=TRUE)) +
    scale_size_continuous(range=c(2, 10)) +theme_minimal() + xlab("FoldEnrichment") +
    ylab(NULL) + ggtitle("Enriched KEGG - FE")
  
  listkegg = list(ek1, ek2, ek3, ek4, ek5, ek6, ek7)
  
  enrichlist = list("egoKEGG" = ekegg,
                    "ekeggplot" = listkegg)
  return(enrichlist)
}


############# GSEA with GO (clusterprofiler) ######################
ggosummary = function (gene0, pcutoff, adjmethod, ont){
  g.go.bp = c()
  g.go.bp = gseGO(geneList = gene0, 
                  ont =ont, # options: All, BP (biol process), MF (mol func), CC (cytosolic comp)
                  keyType = "SYMBOL", 
                  OrgDb = org.Mm.eg.db, 
                  nPerm = 10000, # permutations, set 10,000 when correct
                  minGSSize = 10, # min number genes in set
                  maxGSSize = 1000, # max genes in a set
                  pvalueCutoff = pcutoff,
                  verbose = FALSE, 
                  seed = 42,
                  pAdjustMethod = adjmethod)
  
  ggo.bp = filter(g.go.bp, p.adjust < 0.05, qvalues < 0.05)
  x2.bp = pairwise_termsim(ggo.bp)
  
  ggo.bp1 = as.data.frame(ggo.bp)
  ggo.bp1 = ggo.bp1 %>% dplyr::mutate(log.p.adj = -log(p.adjust)) %>% arrange(ggo.bp1, NES)
  ggo.bp1$Pathway.Direction = cut(-1*ggo.bp1$NES, c(-Inf,0,Inf), c("Upregulated", "Suppressed"))
  colnames(ggo.bp1)[4] = "Count"
  ggo.bp1 = removecrap(ggo.bp1)
  
  
  pg1.bp = dotplot(ggo.bp, showCategory = 20, title = "GSEA-GO", split = ".sign") + facet_grid(.~.sign)
  pg2.bp = gseaplot(ggo.bp, by = "all", geneSetID = 1)
  pg3.bp = ridgeplot(ggo.bp) + labs(x = "enrichment distribution")
  pg4.bp = emapplot(x2.bp)
  pg5.bp = ggplot(ggo.bp1, aes(x = log.p.adj, y = Description)) + 
    geom_point(aes(color= p.adjust, size = setSize)) + theme_bw() + 
    geom_vline(xintercept  = 0, linetype = "dashed")+
    scale_color_viridis_c(guide=guide_colorbar(reverse=TRUE)) + 
    theme(axis.text.y = element_text(size = 10)) +xlab("-log10 of P-value") +
    ylab("Description") + 
    ggtitle("GSEA-GO:BP") + 
    facet_grid(~Pathway.Direction)
  pg6.bp = cnetplot(x2.bp, categorySize = "p.adjust", 
                    colorEdge = TRUE, foldChange = gene0, 
                    node_label = "all", cex_label_category = 1.3)
  
  listgsego.bp = list(pg1.bp, pg2.bp, pg3.bp, pg4.bp, pg5.bp, pg6.bp)
  
  gselist = list("gsego.bp" = ggo.bp, "gsegoplot.bp" = listgsego.bp)
  # "gsego.mf" = ggo.mf, "gsegoplot.mf" = listgsego.mf)
  # # "gsego.cc" = ggo.cc, "gsegoplot.cc" = listgsego.cc)
  
  return(gselist)
}

custom.gsea = function(data){
  test1 = data.frame(data)
  test1 = test1 %>% dplyr::mutate(log.p.adj = -log(p.adjust)) %>% arrange(test1, NES)
  test1$Pathway.Direction = cut(-1*test1$NES, c(-Inf,0,Inf), c("Upregulated", "Suppressed"))
  test1 = removecrap(test1)
  return(test1)
}


############# GSEA with KEGG (clusterprofiler)###################
gkeggsummary = function (gene0, pcutoff, adjmethod){
  pcutoff = 0.05
  adjmethod = "BH"
  
  g.kegg = c()
  g.kegg = gseKEGG(geneList  = gene0,
                   organism = "mmu",
                   keyType = "kegg",
                   minGSSize = 5,
                   maxGSSize = 1000,
                   pvalueCutoff = pcutoff,
                   pAdjustMethod = adjmethod,
                   verbose      = FALSE)
  
  gkegg = c()
  x2 = c()
  gkegg = filter(g.kegg, p.adjust < 0.05, qvalues < 0.05)
  x2 = pairwise_termsim(gkegg)
  
  pk1 = dotplot(gkegg, showCategory = 20, title = "GSEA-kegg", split = ".sign") + facet_grid(.~.sign)
  pk2 = gseaplot(gkegg, by = "all", title = gkegg$Description[1], geneSetID = 1)
  pk3 = ridgeplot(gkegg, showCategory = 20) + labs(x = "enrichment distribution")
  # pk4 = emapplot(x2)
  
  listgsego = list(pk1, pk2, pk3)
  gselist = list("gsekegg" = gkegg, "gsekeggplot" = listgsego)
  
  return(gselist)
}

#### PathfindR pathway analysis for non human species ########
pathsummary = function (clustxvsy){
  clustxvsypath = clustxvsy[,c("symbol", "avg_log2FC", "p_val_adj")]
  pathrun = c()
  pathrun = run_pathfindR(clustxvsypath,
                          enrichment_threshold = 0.01,
                          gene_sets = "Custom",
                          custom_genes = mmu_kegg_genes,
                          custom_descriptions = mmu_kegg_descriptions,
                          output_dir = "pathfind")
  
  tablepath = knitr::kable(head(pathrun, 20))
  chartpath = enrichment_chart(result_df = pathrun, top_terms = 20)
  genepath = term_gene_graph(result_df = pathrun, use_description = TRUE)  
  heatpath = term_gene_heatmap(result_df = pathrun, genes_df = clustxvsypath)
  upsetpath = UpSet_plot(result_df = pathrun, genes_df = clustxvsypath)
  
  plotpath = list(tablepath, chartpath, genepath, heatpath, upsetpath)
  listpath = list("pathway" = pathrun, "pathway plots" = plotpath)
  
  return(listpath)}



####### summary for each pairwise cluster enrichment analysis #####
summary.clustpw = function (i) {
  if (i == 0) {
    clust = se.clust.vs.0
  } else if (i == 1) {
    clust = se.clust.vs.1
  } else if (i == 2) {
    clust = se.clust.vs.1
  } else if (i == 3) {
    clust = se.clust.vs.1
  } else if (i == 4) {
    clust = se.clust.vs.1
  } else if (i == 5) {
    clust = se.clust.vs.1
  } else if (i == 6) {
    clust = se.clust.vs.1
  } else if (i == 7) {
    clust = se.clust.vs.1
  } else if (i == 8) {
    clust = se.clust.vs.1
  } else if (i == 9) {
    clust = se.clust.vs.1
  } else if (i == 10) {
    clust = se.clust.vs.1
  } 
  
  no.clusters = c()
  no.clusters=as.numeric(levels(se@meta.data$seurat_clusters))
  t1 = c()
  t1 = (i+1):no.clusters[length(no.clusters)]
  cxor.temp = c()
  gxor.temp = c()
  cego = c()
  cekegg = c()
  
  cxgse.temp = c()
  gxgse = c()
  cggo = c()
  cgkegg = c()
  cpfr = c()
  
  for (j in t1) {
    cxor.temp[[j]] = clustpwup(clust, i, j)
    gxor.temp[[j]] = gene0entrezid(cxor.temp[[j]])
    cego[[k]] = egosummary(gxor.temp[[j]], 0.05, 0.05, "BH")
    cekegg[[j]] = ekeggsummary(gxor.temp[[j]], 0.05, 0.05, "BH")
    
    cxgse.temp[[j]] = clustpwall(clust, i, j)
    gxgse[[j]] = gene0entrezid(cxgse.temp[[j]])
    cggo[[j]] = ggosummary(gxgse[[j]], 0.05, "BH")
    cgkegg[[j]] = gkeggsummary(gxgse[[j]], 0.05, "BH")
    
    cpfr[[j]] = pathsummary(cxgse.temp[[j]])
  }
  
  matrices = list(cego, cekegg, cpfr)
  return(matrices)}

######## modified violin plots #########
modify_vlnplot<- function(obj, feature, pt.size = 0, 
                          plot.margin = unit(c(-0.75, 0, -0.75, 0), "cm"),
                          ...) {
  p<- VlnPlot(obj, features = feature, pt.size = pt.size, ... )  + 
    xlab("") + ylab(feature) + ggtitle("") + 
    theme(legend.position = "none", 
          axis.text.x = element_blank(), 
          axis.ticks.x = element_blank(),
          axis.title.y = element_text(size = rel(1), angle = 0), 
          axis.text.y = element_text(size = rel(1)), 
          plot.margin = plot.margin ) 
  return(p)
}

extract_max<- function(p){
  ymax<- max(ggplot_build(p)$layout$panel_scales_y[[1]]$range$range)
  return(ceiling(ymax))
}

StackedVlnPlot<- function(obj, features,
                          pt.size = 0, 
                          plot.margin = unit(c(-0.75, 0, -0.75, 0), "cm"),
                          ...) {
  
  plot_list<- purrr::map(features, function(x) modify_vlnplot(obj = obj,feature = x, ...))
  
  # Add back x-axis title to bottom plot. patchwork is going to support this?
  plot_list[[length(plot_list)]]<- plot_list[[length(plot_list)]] +
    theme(axis.text.x=element_text(angle = 45, hjust = 1, vjust = 1), 
          axis.ticks.x = element_line())
  
  # change the y-axis tick to only max value 
  ymaxs<- purrr::map_dbl(plot_list, extract_max)
  plot_list<- purrr::map2(plot_list, ymaxs, function(x,y) x + 
                            scale_y_continuous(breaks = c(y)) + 
                            expand_limits(y = y))
  
  p<- patchwork::wrap_plots(plotlist = plot_list, ncol = 1)
  return(p)
}

###### Plot genes of interest on spatial sets ###########
dispgoi = function(se, ftx, splitby) {
  
  fdisp = c()
  for (i in 1:length(ftx)) {
    if (splitby == "treatment") {
      fdisp[[i]] = FeaturePlot(se, features = ftx[[i]], reduction = "umap", order = TRUE, 
                               cols = heatmap.colors, split.by = "treatment", ncol = 3)
    } else if (splitby == "slide") {
      fdisp[[i]] = FeaturePlot(se, features = ftx[[i]], reduction = "umap", order = TRUE, 
                               cols = heatmap.colors, split.by = "slide", ncol = 3)
    } else {
      fdisp[[i]] = FeatureOverlay(se, features = ftx[[i]], sampleids = 1:6, 
                                  cols = c("lightgray", "mistyrose", "red", "darkred", "black"), 
                                  pt.size = 1.5,  pt.alpha = 0.5, ncol = 3)
    }}
  
  return(fdisp)
}


######## Gsea for LPSTolDC vs other groups #########
gsea.lpstol.v.rest.03 = function(se, cluster,threshold){
  id1 = "LPSTol"
  id2 = "TolDC"
  id3 = "PBS"
  check = c()
  check = SubsetSTData(se, expression = SCT_snn_res.0.3 == cluster)
  Idents(check) = 'SCT_snn_res.0.3'
  
  check.pbs = SubsetSTData(check, expression = treatment == "PBS")
  check.ltoldc = SubsetSTData(check, expression = treatment == "LPSTol")
  check.toldc = SubsetSTData(check, expression = treatment == "TolDC")
  check.m = MergeSTData(check.pbs,c(check.toldc,  check.ltoldc))
  
  # Cluster 7 FindMarkers id1 (LPS-Tol) vs id2 (TolDC)
  check.markers.id1v2 = c()
  check.markers.id1v2 = FindMarkers(check.m, ident.1 = id1, ident.2 = id2, 
                                    group.by = 'treatment', 
                                    subset.ident = as.character(cluster), 
                                    recorrect_umi = FALSE,
                                    logfc.threshold = threshold, 
                                    min.pct = 0.05)
  check.markers.id1v2 = clustpprocess(check.markers.id1v2)
  
  volcanoid1v2 = ggplot(data=check.markers.id1v2, 
                        aes(x=avg_log2FC, y=-log10(p_val_adj), 
                            col=diffexpressed, label=dlabel)) +
    geom_point() + theme_minimal() + geom_text_repel() +
    scale_color_manual(values=c("blue", "black", "red")) +
    geom_vline(xintercept=c(-0.5, 0.5), col="pink") +
    geom_hline(yintercept=-log10(0.05), col="pink") + 
    ggtitle("LPSTolDC vs TolDC")
  
  # GSE analysis
  c0v1ggo.id1v2bp = c()
  c0v1ggo.id1v2bp = ggosummarybp(gene0symbol(check.markers.id1v2), 0.05, "BH", "all")
  
  test1 = data.frame(c0v1ggo.id1v2bp$gsego.bp)
  test1 = test1 %>% dplyr::mutate(log.p.adj = -log(p.adjust)) %>% arrange(test1, NES)
  test1$Pathway.Direction = cut(-1*test1$NES, c(-Inf,0,Inf), c("Upregulated", "Suppressed"))
  test1 = removecrap(test1)
  test1.a = pickimmune(test1)
  
  # Cluster 7 FindMarkers id1 (LPS-Tol) vs id3 (PBS)
  check.markers.id1v3 = c()
  check.markers.id1v3 = FindMarkers(check.m, ident.1 = id1, ident.2 = id3, 
                                    group.by = 'treatment', 
                                    subset.ident = as.character(cluster), 
                                    recorrect_umi = FALSE,
                                    logfc.threshold = threshold, 
                                    min.pct = 0.05)
  check.markers.id1v3 = clustpprocess(check.markers.id1v3)
  
  volcanoid1v3 = c()
  volcanoid1v3 = ggplot(data=check.markers.id1v3, 
                        aes(x=avg_log2FC, y=-log10(p_val_adj), 
                            col=diffexpressed, label=dlabel)) +
    geom_point() + theme_minimal() + geom_text_repel() +
    scale_color_manual(values=c("blue", "black", "red")) +
    geom_vline(xintercept=c(-0.5, 0.5), col="pink") +
    geom_hline(yintercept=-log10(0.05), col="pink") + 
    ggtitle("LPSTolDC vs PBS")
  
  # GSE analysis
  c0v1ggo.id1v3bp = ggosummarybp(gene0symbol(check.markers.id1v3), 0.05, "BH", "all")
  
  test2 = data.frame(c0v1ggo.id1v3bp$gsego.bp)
  test2 = test2 %>% dplyr::mutate(log.p.adj = -log(p.adjust)) %>% arrange(test2, NES)
  test2$Pathway.Direction = cut(-1*test2$NES, c(-Inf,0,Inf), c("Upregulated", "Suppressed"))
  test2 = removecrap(test2)
  test2.a = pickimmune(test2)
  
  # Find common for Cluster 7 LPSTol vs Tol/PBS
  common = test1[test1$Description %in% test2$Description,]
  common.keep = common[common$Pathway.Direction == test2$Pathway.Direction,]
  common.keep = common.keep[!is.na(common.keep$Pathway.Direction),]
  remove = common.keep$Description[grep("anatomical", common.keep$Description, ignore.case = TRUE)]
  common.keep = common.keep[!(common.keep$Description %in% remove),]
  
  list1 = list(test1, test1.a, test2, test2.a, common.keep)
  return(list1)}

custom.gsea = function(data){
  test1 = data.frame(data)
  test1 = test1 %>% dplyr::mutate(log.p.adj = -log(p.adjust)) %>% arrange(test1, NES)
  test1$Pathway.Direction = cut(-1*test1$NES, c(-Inf,0,Inf), c("Upregulated", "Suppressed"))
  test1 = removecrap(test1)
  return(test1)
}

############# further process and filter for digestible results ################
trimmer = function(data){
  data = data[data$p.adjust < 0.05,]
  
  data = data[!(data$Description == "viral entry into host cell"),]
  data = data[!(data$Description == "neuroinflammatory response"),]
  data = data[!(data$Description == "immune response"),]
  data = data[!(data$Description == "immune system process"),]
  data = data[!(data$Description == "enzyme linked receptor protein signaling pathway"),]
  data = data[!(data$Description == "inflammatory response"),]
  data = data[!(data$Description == "tissue migration"),]
  data = data[!(data$Description == "movement in host environment"),]
  
  remove = c(data$Description[grep("regulation",  data$Description, ignore.case = TRUE)],  
             data$Description[grep("epithelium",  data$Description, ignore.case = TRUE)],
             data$Description[grep("projection",  data$Description, ignore.case = TRUE)],
             data$Description[grep("sprouting",  data$Description, ignore.case = TRUE)],
             data$Description[grep("complex I",   data$Description, ignore.case = TRUE)], 
             data$Description[grep("plasma membrane",   data$Description, ignore.case = TRUE)],
             data$Description[grep("cellular lipid",   data$Description, ignore.case = TRUE)],
             data$Description[grep("locomotion",   data$Description, ignore.case = TRUE)],
             data$Description[grep("adhesion",   data$Description, ignore.case = TRUE)],
             data$Description[grep("protein",   data$Description, ignore.case = TRUE)],
             data$Description[grep("migration",   data$Description, ignore.case = TRUE)])
  data = data[!(data$Description %in% remove),]
  
  myeloid = c(data$Description[grep("myeloid", data$Description, ignore.case = TRUE)],
              data$Description[grep("monocyte", data$Description, ignore.case = TRUE)], 
              data$Description[grep("mononuclear", data$Description, ignore.case = TRUE)], 
              data$Description[grep("macrophage", data$Description, ignore.case = TRUE)], 
              data$Description[grep("granulocyte", data$Description, ignore.case = TRUE)], 
              data$Description[grep("dendritic", data$Description, ignore.case = TRUE)], 
              data$Description[grep("neutrophil", data$Description, ignore.case = TRUE)],
              data$Description[grep("tumour", data$Description, ignore.case = TRUE)],
              data$Description[grep("tumor", data$Description, ignore.case = TRUE)],
              data$Description[grep("antigen", data$Description, ignore.case = TRUE)],
              data$Description[grep("neutrophil", data$Description, ignore.case = TRUE)],
              data$Description[grep("innate", data$Description, ignore.case = TRUE)])
  
  lymphoid = c(data$Description[grep("lymphocyte", data$Description, ignore.case = TRUE)],
               data$Description[grep("leukocyte", data$Description, ignore.case = TRUE)], 
               data$Description[grep("T cell", data$Description, ignore.case = TRUE)], 
               data$Description[grep("B cell", data$Description, ignore.case = TRUE)], 
               data$Description[grep("effector", data$Description, ignore.case = TRUE)], 
               data$Description[grep("adaptive", data$Description, ignore.case = TRUE)])
  lymphoid = lymphoid[!(lymphoid %in% myeloid)]
  
  c.death = c(data$Description[grep("death", data$Description, ignore.case = TRUE)],
              data$Description[grep("apoptotic", data$Description, ignore.case = TRUE)],
              data$Description[grep("platelet", data$Description, ignore.case = TRUE)],
              data$Description[grep("immune", data$Description, ignore.case = TRUE)])
  
  metab = c(data$Description[grep("oxidation", data$Description, ignore.case = TRUE)],
            data$Description[grep("oxidative", data$Description, ignore.case = TRUE)],
            data$Description[grep("oxygen", data$Description, ignore.case = TRUE)],
            data$Description[grep("heme", data$Description, ignore.case = TRUE)],
            data$Description[grep("fatty", data$Description, ignore.case = TRUE)],
            data$Description[grep("lipid", data$Description, ignore.case = TRUE)],
            data$Description[grep("iron", data$Description, ignore.case = TRUE)],
            data$Description[grep("respiratory", data$Description, ignore.case = TRUE)],
            data$Description[grep("oxidoreductase", data$Description, ignore.case = TRUE)], 
            data$Description[grep("dehydrogenase", data$Description, ignore.case = TRUE)], 
            data$Description[grep("glutathione", data$Description, ignore.case = TRUE)], 
            data$Description[grep("NAD", data$Description, ignore.case = TRUE)], 
            data$Description[grep("tricarboxylic", data$Description, ignore.case = TRUE)], 
            data$Description[grep("respirasome", data$Description, ignore.case = TRUE)],
            data$Description[grep("respiration", data$Description, ignore.case = TRUE)],
            data$Description[grep("electron", data$Description, ignore.case = TRUE)], 
            data$Description[grep("mitochondrial", data$Description, ignore.case = TRUE)], 
            data$Description[grep("mitochondria", data$Description, ignore.case = TRUE)])
  
  adh.cycle = c(data$Description[grep("adhesion", data$Description, ignore.case = TRUE)],
                data$Description[grep("epithelial", data$Description, ignore.case = TRUE)],
                data$Description[grep("angiogenesis", data$Description, ignore.case = TRUE)],
                data$Description[grep("mitotic", data$Description, ignore.case = TRUE)],
                data$Description[grep("exocytosis", data$Description, ignore.case = TRUE)],
                data$Description[grep("membrane", data$Description, ignore.case = TRUE)],
                data$Description[grep("fibroblast", data$Description, ignore.case = TRUE)],
                data$Description[grep("endothelial", data$Description, ignore.case = TRUE)],
                data$Description[grep("polarity", data$Description, ignore.case = TRUE)],
                data$Description[grep("phosphatidylinositol", data$Description, ignore.case = TRUE)],
                data$Description[grep("cycle", data$Description, ignore.case = TRUE)])
  adh.cycle = adh.cycle[!(adh.cycle%in% metab)]
  adh.cycle = adh.cycle[!(adh.cycle%in% c.death)]
  
  data$group  = NA
  data$group = ifelse(data$Description %in% myeloid, "innate", data$group)
  data$group = ifelse(data$Description %in% lymphoid, "adaptive", data$group)
  data$group = ifelse(data$Description %in% metab, "metab", data$group)
  data$group = ifelse(data$Description %in% adh.cycle, "cell", data$group)
  data$group = ifelse(data$Description %in% c.death, "death", data$group)
  
  return(data)}

set.seed(42)
```

giotto.setup.R
```{r, eval = FALSE}
# Make function for basic giotto processing to apply to all slides - giotto.basics
# 1. set working directory
results_folder = '/giotto/'

# 2. set giotto python path
python_path = NULL 
if(is.null(python_path)) {
  installGiottoEnvironment()}

## create global instructions
instrs = createGiottoInstructions(save_dir = results_folder,
                                  save_plot = FALSE,
                                  show_plot = FALSE,
                                  python_path = python_path)


# Create giotto objects and join
kidney.a = createGiottoVisiumObject(
  expr_data = "filter", 
  h5_visium_path = "giotto/A/filtered_feature_bc_matrix.h5",
  h5_image_png_path = "giotto/A/tissue_lowres_image.png",
  h5_tissue_positions_path = "giotto/A/tissue_positions_list.csv", 
  instructions = instrs) # D53

# Check alignment  and meta-data  for each
spatPlot(gobject = kidney.a, 
         cell_color = 'in_tissue', 
         show_image = T, point_alpha = 0.7)
showGiottoImageNames(kidney.a) # "image" is the default name
kidney.a = updateGiottoImage(kidney.a, image_name = 'image',
                             xmax_adj = 150, xmin_adj = 150,
                             ymax_adj = 458, ymin_adj = 415)
spatPlot(gobject = kidney.a, cell_color = 'in_tissue', 
         show_image = T, point_alpha = 0.7)

pDataDT(kidney.a)
spatPlot(gobject = kidney.a, 
         cell_color = 'in_tissue', point_size = 2,
         cell_color_code = c('0' = 'lightgrey', '1' = 'blue'))
metadata.a = pDataDT(kidney.a)
in_tissue_barcodes.a = metadata.a[in_tissue == 1]$cell_ID
kidney.a = subsetGiotto(kidney.a, cell_ids = in_tissue_barcodes.a)
gc()

kidney.b = createGiottoVisiumObject(
  expr_data = "filter", 
  h5_visium_path = "giotto/B/filtered_feature_bc_matrix.h5",
  h5_image_png_path = "giotto/B/tissue_lowres_image.png",
  h5_tissue_positions_path = "giotto/B/tissue_positions_list.csv", 
  instructions = instrs) # D54

# Check alignment  and meta-data  for each
spatPlot(gobject = kidney.b, 
         cell_color = 'in_tissue', 
         show_image = T, point_alpha = 0.7)
showGiottoImageNames(kidney.b) # "image" is the default name
kidney.b = updateGiottoImage(kidney.b, image_name = 'image',
                             xmax_adj = 160, xmin_adj = 180,
                             ymax_adj = 365, ymin_adj = 365)
spatPlot(gobject = kidney.b, cell_color = 'in_tissue', 
         show_image = T, point_alpha = 0.7)

pDataDT(kidney.b)
spatPlot(gobject = kidney.b, 
         cell_color = 'in_tissue', point_size = 2,
         cell_color_code = c('0' = 'lightgrey', '1' = 'blue'))
metadata.b = pDataDT(kidney.b)
in_tissue_barcodes.b = metadata.b[in_tissue == 1]$cell_ID
kidney.b = subsetGiotto(kidney.b, cell_ids = in_tissue_barcodes.b)
gc()

kidney.c = createGiottoVisiumObject(
  expr_data = "filter", 
  h5_visium_path = "giotto/C/filtered_feature_bc_matrix.h5",
  h5_image_png_path = "giotto/C/tissue_lowres_image.png",
  h5_tissue_positions_path = "giotto/C/tissue_positions_list.csv", 
  instructions = instrs) # D17

# Check alignment  and meta-data  for each
spatPlot(gobject = kidney.c, 
         cell_color = 'in_tissue', 
         show_image = T, point_alpha = 0.7)
showGiottoImageNames(kidney.c) # "image" is the default name
kidney.c = updateGiottoImage(kidney.c, image_name = 'image',
                             xmax_adj = 150, xmin_adj = 130,
                             ymax_adj = 300, ymin_adj = 110)
spatPlot(gobject = kidney.c, cell_color = 'in_tissue', 
         show_image = T, point_alpha = 0.7)

pDataDT(kidney.c)
spatPlot(gobject = kidney.c, 
         cell_color = 'in_tissue', point_size = 2,
         cell_color_code = c('0' = 'lightgrey', '1' = 'blue'))
metadata.c = pDataDT(kidney.c)
in_tissue_barcodes.c = metadata.c[in_tissue == 1]$cell_ID
kidney.c = subsetGiotto(kidney.c, cell_ids = in_tissue_barcodes.c)
gc()

kidney.d = createGiottoVisiumObject(
  expr_data = "filter", 
  h5_visium_path = "giotto/D/filtered_feature_bc_matrix.h5",
  h5_image_png_path = "giotto/D/tissue_lowres_image.png",
  h5_tissue_positions_path = "giotto/D/tissue_positions_list.csv", 
  instructions = instrs) # D19

# Check alignment  and meta-data  for each
spatPlot(gobject = kidney.d, 
         cell_color = 'in_tissue', 
         show_image = T, point_alpha = 0.7)
showGiottoImageNames(kidney.d) # "image" is the default name
kidney.d = updateGiottoImage(kidney.d, image_name = 'image',
                             xmax_adj = 150, xmin_adj = 150,
                             ymax_adj = 335, ymin_adj = 450)
spatPlot(gobject = kidney.d, cell_color = 'in_tissue', 
         show_image = T, point_alpha = 0.7)

pDataDT(kidney.d)
spatPlot(gobject = kidney.d, 
         cell_color = 'in_tissue', point_size = 2,
         cell_color_code = c('0' = 'lightgrey', '1' = 'blue'))
metadata.d = pDataDT(kidney.d)
in_tissue_barcodes.d = metadata.d[in_tissue == 1]$cell_ID
kidney.d = subsetGiotto(kidney.d, cell_ids = in_tissue_barcodes.d)
gc()

kidney.e = createGiottoVisiumObject(
  expr_data = "filter", 
  h5_visium_path = "giotto/E/filtered_feature_bc_matrix.h5",
  h5_image_png_path = "giotto/E/tissue_lowres_image.png",
  h5_tissue_positions_path = "giotto/E/tissue_positions_list.csv", 
  instructions = instrs) # D12

# Check alignment  and meta-data  for each
spatPlot(gobject = kidney.e, 
         cell_color = 'in_tissue', 
         show_image = T, point_alpha = 0.7)
showGiottoImageNames(kidney.e) # "image" is the default name
kidney.e = updateGiottoImage(kidney.e, image_name = 'image',
                             xmax_adj = 610, xmin_adj = 590,
                             ymax_adj = 500, ymin_adj = 180)
spatPlot(gobject = kidney.e, cell_color = 'in_tissue', 
         show_image = T, point_alpha = 0.7)

pDataDT(kidney.e)
spatPlot(gobject = kidney.e, 
         cell_color = 'in_tissue', point_size = 2,
         cell_color_code = c('0' = 'lightgrey', '1' = 'blue'))
metadata.e = pDataDT(kidney.e)
in_tissue_barcodes.e = metadata.e[in_tissue == 1]$cell_ID
kidney.e = subsetGiotto(kidney.e, cell_ids = in_tissue_barcodes.e)
gc()

kidney.f = createGiottoVisiumObject(
  expr_data = "filter", 
  h5_visium_path = "giotto/F/filtered_feature_bc_matrix.h5",
  h5_image_png_path = "giotto/F/tissue_lowres_image.png",
  h5_tissue_positions_path = "giotto/F/tissue_positions_list.csv", 
  instructions = instrs) # D20

# Check alignment  and meta-data  for each
spatPlot(gobject = kidney.f, 
         cell_color = 'in_tissue', 
         show_image = T, point_alpha = 0.7)
showGiottoImageNames(kidney.f) # "image" is the default name
kidney.f = updateGiottoImage(kidney.f, image_name = 'image',
                             xmax_adj = 630, xmin_adj = 990,
                             ymax_adj = 335, ymin_adj = 280)
spatPlot(gobject = kidney.f, cell_color = 'in_tissue', 
         show_image = T, point_alpha = 0.7)

pDataDT(kidney.f)
spatPlot(gobject = kidney.f, 
         cell_color = 'in_tissue', point_size = 2,
         cell_color_code = c('0' = 'lightgrey', '1' = 'blue'))
metadata.f = pDataDT(kidney.f)
in_tissue_barcodes.f = metadata.f[in_tissue == 1]$cell_ID
kidney.f = subsetGiotto(kidney.f, cell_ids = in_tissue_barcodes.f)
gc()

# # join giotto objects. joining with x_shift has the advantage that you can join both 2D and 3D data. x_padding determines how much distance is between each dataset. if x_shift = NULL, then the total shift will be guessed from the giotto image - USE WHEN GIOTTO SUITE WORKS
# kidney.combined = joinGiottoObjects(gobject_list = 
#                                 list(kidney.a, kidney.b, 
#                                      kidney.c, kidney.d,
#                                      kidney.e, kidney.f),
#     gobject_names = c('A', 'B', 'C', 'D', 'E', 'F'),
#     join_method = 'shift', x_padding = 1000)
# 
# 
# # join info is stored in this slot
# # simple list for now
# testcombo@join_info
# 
# 
# # check joined Giotto object
# fDataDT(testcombo)
# pDataDT(testcombo)
# showGiottoImageNames(testcombo)
# showGiottoSpatLocs(testcombo)
# showGiottoExpression(testcombo)

saveRDS(kidney.a, "giotto/rds/kidney.a.raw.rds")
saveRDS(kidney.b, "giotto/rds/kidney.b.raw.rds")
saveRDS(kidney.c, "giotto/rds/kidney.c.raw.rds")
saveRDS(kidney.d, "giotto/rds/kidney.d.raw.rds")
saveRDS(kidney.e, "giotto/rds/kidney.e.raw.rds")
saveRDS(kidney.f, "giotto/rds/kidney.f.raw.rds")

# basic processing
kidney.visium.a = giotto.basics(kidney.a, 'network')
saveRDS(kidney.visium.a, "giotto/rds/kidney.a.rds")
gc()

gc()
kidney.visium.b = giotto.basics(kidney.b, 'network')
saveRDS(kidney.visium.b, "giotto/rds/kidney.b.rds")


gc()
kidney.visium.c = giotto.basics(kidney.c, 'network')
saveRDS(kidney.visium.c, "giotto/rds/kidney.c.rds")

gc()
kidney.visium.d = giotto.basics(kidney.d, 'network')
saveRDS(kidney.visium.d, "giotto/rds/kidney.d.rds")

gc()
kidney.visium.e = giotto.basics(readRDS("giotto/rds/kidney.e.raw.rds"), 'grid') # network becomes out of bounds
saveRDS(kidney.visium.e, "giotto/rds/kidney.e.rds")

gc()
kidney.visium.f = giotto.basics(kidney.f, 'grid') # network becomes out of bounds
saveRDS(kidney.visium.f, "giotto/rds/kidney.f.rds")



```

processed.spatial.R
```{r, eval = FALSE}
# Load processed data

se = readRDS("rds/se.0.3.rds")

se.markers.all = readRDS("rds/sefindallmarkersFC1.2.rds") 
se.markers.up = readRDS("rds/se.markers.upFC1.2.rds")
se.markers.down = readRDS("rds/se.markers.downFC1.2.rds")
se.markers.all.0 = readRDS("rds/backupcluster.vs.rest.tissue.rds")

genes.all = readRDS("rds/features.rds")
colnames(genes.all) = c("Ensembl", "symbol", "other")
gene.conversions = as.data.frame(se@assays$RNA@meta.features)
gene.conversions$symbol = rownames(gene.conversions)
gene.conversions$ensembl = genes.all$Ensembl[match(gene.conversions$symbol, genes.all$symbol)]

clust.0vs = readRDS("rds/clust0vs.rds")
clust.1vs = readRDS("rds/clust1vs.rds")
clust.2vs = readRDS("rds/clust2vs.rds")
clust.3vs = readRDS("rds/clust3vs.rds")
clust.4vs = readRDS("rds/clust4vs.rds")
clust.5vs = readRDS("rds/clust5vs.rds")
clust.6vs = readRDS("rds/clust6vs.rds")
clust.7vs = readRDS("rds/clust7vs.rds")
clust.8vs = readRDS("rds/clust8vs.rds")

clust0.treatment = readRDS("rds/clust.treatment.0.rds")
clust1.treatment = readRDS("rds/clust.treatment.1.rds")
clust2.treatment = readRDS("rds/clust.treatment.2.rds")
clust3.treatment = readRDS("rds/clust.treatment.3.rds")
clust4.treatment = readRDS("rds/clust.treatment.4.rds")
clust5.treatment = readRDS("rds/clust.treatment.5.rds")
# clust6.treatment = readRDS("rds/clust.treatment.6.rds")
clust7.treatment = readRDS("rds/clust.treatment.7.rds")
clust8.treatment = readRDS("rds/clust.treatment.8.rds")
clust9.treatment = readRDS("rds/clust.treatment.9.rds")
```

scoreMarkers.R
```{r, eval = FALSE}
#' Score marker genes
#' # change from original in scran (in the compute .cross_reference_to_desired - added dataframe() to the average expression! that was the error)
#'
#' Compute various summary scores for potential marker genes to distinguish between groups of cells.
#'
#' @param x A matrix-like object containing log-normalized expression values, with genes in rows and cells in columns.
#' Alternatively, a \linkS4class{SummarizedExperiment} object containing such a matrix in its assays.
#' @param groups A factor or vector containing the identity of the group for each cell in \code{x}.
#' @param block A factor or vector specifying the blocking level for each cell in \code{x}.
#' @param row.data A DataFrame with the same number and names of rows in \code{x}, containing extra information to insert into each DataFrame.
#' @param full.stats Logical scalar indicating whether the statistics from the pairwise comparisons should be directly returned.
#' @param BPPARAM A \linkS4class{BiocParallelParam} object specifying how the calculations should be parallelized.
#' @param ... For the generic, further arguments to pass to individual methods.
#' 
#' For the SummarizedExperiment method, further arguments to pass to the ANY method.
#'
#' For the SingleCellExperiment method, further arguments to pass to the SummarizedExperiment method.
#' @param assay.type String or integer scalar specifying the assay containing the log-expression matrix to use.
#' @param lfc Numeric scalar specifying the log-fold change threshold to compute effect sizes against.
#' @param pairings A vector, list or matrix specifying how the comparisons are to be performed, see details.
#' @param subset.row See \code{?"\link{scran-gene-selection}"}.
#'
#' @return
#' A List of DataFrames containing marker scores for each gene in each group.
#' Each DataFrame corresponds to a group and each row corresponds to a gene in \code{x}.
#' See Details for information about the individual columns.
#'
#' @details
#' Compared to \code{\link{findMarkers}}, this function represents a simpler and more intuitive summary of the differences between the groups.
#' We do this by realizing that the p-values for these types of comparisons are largely meaningless;
#' individual cells are not meaningful units of experimental replication, while the groups themselves are defined from the data.
#' Thus, by discarding the p-values, we can simplify our marker selection by focusing only on the effect sizes between groups.
#' 
#' Here, the strategy is to perform pairwise comparisons between each pair of groups to obtain various effect sizes.
#' For each group \eqn{X}, we summarize the effect sizes across all pairwise comparisons involving that group, e.g., mean, min, max and so on.
#' This yields a DataFrame for each group where each column contains a different summarized effect and each row corresponds to a gene in \code{x}.
#' Reordering the rows by the summary of choice can yield a ranking of potential marker genes for downstream analyses.
#' 
#' @section Choice of effect sizes:
#' The \code{logFC.cohen} columns contain the standardized log-fold change, i.e., Cohen's d.
#' For each pairwise comparison, this is defined as the difference in the mean log-expression for each group scaled by the average standard deviation across the two groups.
#' (Technically, we should use the pooled variance; however, this introduces some unpleasant asymmetry depending on the variance of the larger group, so we take a simple average instead.)
#' Cohen's d is analogous to the t-statistic in a two-sample t-test and avoids spuriously large effect sizes from comparisons between highly variable groups.
#' We can also interpret Cohen's d as the number of standard deviations between the two group means.
#' 
#' The \code{AUC} columns contain the area under the curve.
#' This is the probability that a randomly chosen observation in one group is greater than a randomly chosen observation in the other group.
#' The AUC is closely related to the U-statistic used in the Wilcoxon rank sum test.
#' Values greater than 0.5 indicate that a gene is upregulated in the first group.
#'
#' The key difference between the AUC and Cohen's d is that the former is less sensitive to the variance within each group.
#' The clearest example is that of two distributions that exhibit no overlap, where the AUC is the same regardless of the variance of each distribution.
#' This may or may not be desirable as it improves robustness to outliers but reduces the information available to obtain a highly resolved ranking. 
#' The most appropriate choice of effect size is left at the user's discretion.
#'
#' Finally, the \code{logFC.detected} columns contain the log-fold change in the proportion of cells with detected (i.e., non-zero) expression between groups.
#' This is specifically useful for detecting binary expression patterns, e.g., activation of an otherwise silent gene.
#' Note that the non-zero status of the data is not altered by normalization, so differences in library size will not be removed when computing this metric.
#' This effect is not necessarily problematic - users can interpret it as \emph{retaining} information about the total RNA content, analogous to spike-in normalization.
#'
#' @section Setting a log-fold change threshold:
#' The default settings may yield highly ranked genes with large effect sizes but low log-fold changes if the variance is low (Cohen's d) or separation is clear (AUC).
#' Such genes may not be particularly interesting as the actual change in expression is modest.
#' Setting \code{lfc} allows us to focus on genes with large log-fold changes between groups,
#' by simply shifting the \dQuote{other} group's expression values by \code{lfc} before computing effect sizes.
#'
#' When \code{lfc} is not zero, Cohen's d is generalized to the standardized difference between the observed log-fold change and \code{lfc}.
#' For example, if we had \code{lfc=2} and we obtained a Cohen's d of 3, this means that the observed log-fold change was 3 standard deviations above a value of 2.
#' A side effect is that we can only unambiguously interpret the direction of Cohen's d when it has the same sign as \code{lfc}.
#' Our above example represents upregulation, but if our Cohen's d was negative, this could either mean downregulation or simply that our observed log-fold change was less than \code{lfc}.
#' 
#' When \code{lfc} is not zero, the AUC is generalized to the probability of obtaining a random observation in one group that is greater than a random observation plus \code{lfc} in the other group.
#' For example, if we had \code{lfc=2} and we obtained an AUC of 0.8, this means that we would observe a difference of \code{lfc} or greater between the random observations.
#' Again, we can only unambiguously interpret the direction of the change when it is the same as the sign of the \code{lfc}.
#' In this case, an AUC above 0.5 with a positive \code{lfc} represents upregulation, but an AUC below 0.5 could mean either downregulation or a log-fold change less than \code{lfc}.
#' 
#' A non-zero setting of \code{lfc} has no effect on the log-fold change in the proportion of cells with detected expression.
#' 
#' @section Computing effect size summaries:
#' To simplify interpretation, we summarize the effect sizes across all pairwise comparisons into a few key metrics.
#' For each group \eqn{X}, we consider the effect sizes from all pairwise comparisons between \eqn{X} and other groups. 
#' We then compute the following values:
#' \itemize{
#' \item \code{mean.*}, the mean effect size across all pairwise comparisons involving \eqn{X}.
#' A large value (>0 for log-fold changes, >0.5 for the AUCs) indicates that the gene is upregulated in \eqn{X} compared to the average of the other groups.
#' A small value (<0 for the log-fold changes, <0.5 for the AUCs) indicates that the gene is downregulated in \eqn{X} instead.
#' \item \code{median.*}, the median effect size across all pairwise comparisons involving \eqn{X}.
#' A large value indicates that the gene is upregulated in \eqn{X} compared to most (>50\%) other groups.
#' A small value indicates that the gene is downregulated in \eqn{X} instead.
#' \item \code{min.*}, the minimum effect size across all pairwise comparisons involving \eqn{X}.
#' A large value indicates that the gene is upregulated in \eqn{X} compared to all other groups.
#' A small value indicates that the gene is downregulated in \eqn{X} compared to at least one other group.
#' \item \code{max.*}, the maximum effect size across all pairwise comparisons involving \eqn{X}.
#' A large value indicates that the gene is upregulated in \eqn{X} compared to at least one other group.
#' A small value indicates that the gene is downregulated in \eqn{X} compared to all other groups.
#' \item \code{rank.*}, the minimum rank (i.e., \dQuote{min-rank}) across all pairwise comparisons involving \eqn{X} - see \code{?\link{computeMinRank}} for details.
#' A small min-rank indicates that the gene is one of the top upregulated genes in at least one comparison to another group.
#' }
#' One set of these columns is added to the DataFrame for each effect size described above.
#' For example, the mean column for the AUC would be \code{mean.AUC}.
#' We can then reorder each group's DataFrame by our column of choice, depending on which summary and effect size we are interested in.
#' For example, if we ranked by decreasing \code{min.logFC.detected}, we would be aiming for marker genes that exhibit strong binary increases in expression in \eqn{X} compared to \emph{all} other groups.
#' 
#' If \code{full.stats=TRUE}, an extra \code{full.*} column is returned in the DataFrame.
#' This contains a nested DataFrame with number of columns equal to the number of other groups.
#' Each column contains the statistic from the comparison between \eqn{X} and the other group.
#'
#' Keep in mind that the interpretations above also depend on the sign of \code{lfc}.
#' The concept of a \dQuote{large} summary statistic (>0 for Cohen's d, >0.5 for the AUCs) can only be interpreted as upregulation when \code{lfc >= 0}.
#' Similarly, the concept of a \dQuote{small} value (<0 for Cohen's d, <0.5 for the AUCs) cannot be interpreted as downregulation when \code{lfc <= 0}.
#' For example, if \code{lfc=1}, a positive \code{min.logFC.cohen} can still be interpreted as upregulation in \eqn{X} compared to all other groups,
#' but a negative \code{max.logFC.cohen} could not be interpreted as downregulation in \eqn{X} compared to all other groups.
#'
#' @section Computing other descriptive statistics: 
#' We report the mean log-expression of all cells in \eqn{X}, as well as the grand mean of mean log-expression values for all other groups.
#' This is purely descriptive; while it can be used to compute an overall log-fold change, ranking is best performed on one of the effect sizes described above.
#' We also report the proportion of cells with detectable expression in \eqn{X} and the mean proportion for all other groups.
#'
#' When \code{block} is specified, the reported mean for each group is computed via \code{\link{correctGroupSummary}}. 
#' Briefly, this involves fitting a linear model to remove the effect of the blocking factor from the per-group mean log-expression.
#' The same is done for the detected proportion, except that the values are subjected to a logit transformation prior to the model fitting.
#' In both cases, each group/block combination is weighted by its number of cells in the model.
#'
#' @section Controlling the pairings:
#' The \code{pairings} argument specifies the pairs of groups that should be compared.
#' This can be:
#' \itemize{
#' \item \code{NULL}, in which case comparisons are performed between all groups in \code{groups}.
#' \item A vector of the same type as \code{group}, specifying a subset of groups of interest.
#' We then perform all pairwise comparisons between groups in the subset.
#' \item A list of two vectors, each of the same type as \code{group} and specifying a subset of groups.
#' Comparisons are performed between one group from the first vector and another group from the second vector.
#' \item A matrix of two columns of the same type as \code{group}.
#' Each row is assumed to specify a pair of groups to be compared.
#' }
#' 
#' Effect sizes (and their summaries) are computed for only the pairwise comparisons specified by \code{pairings}.
#' Similarly, the \code{other.*} values in \eqn{X}'s DataFrame are computed using only the groups involved in pairwise comparisons with \eqn{X}.
#' The default of \code{pairings=NULL} ensures that all groups are used and effect sizes for all pairwise comparisons are reported;
#' however, this may not be the case for other values of \code{pairings}.
#' 
#' For list and matrix arguments, the first vector/column is treated as the first group in the effect size calculations.
#' Statistics for each comparison will only show up in the DataFrame for the first group, 
#' i.e., a comparison between \eqn{X} and \eqn{Y} will have a valid \code{full.AUC$Y} field in \eqn{X}'s DataFrame but not vice versa.
#' If both directions are desired in the output, both of the corresponding permutations should be explicitly specified in \code{pairings}.
#' 
#' @author Aaron Lun
#' 
#' @examples
#' library(scuttle)
#' sce <- mockSCE()
#' sce <- logNormCounts(sce)
#'
#' # Any clustering method is okay, only using k-means for convenience.
#' kout <- kmeans(t(logcounts(sce)), centers=4) 
#' 
#' out <- scoreMarkers(sce, groups=kout$cluster)
#' out
#'
#' # Ranking by a metric of choice:
#' of.interest <- out[[1]]
#' of.interest[order(of.interest$mean.AUC, decreasing=TRUE),1:4]
#' of.interest[order(of.interest$rank.AUC),1:4]
#' of.interest[order(of.interest$median.logFC.cohen, decreasing=TRUE),1:4]
#' of.interest[order(of.interest$min.logFC.detected, decreasing=TRUE),1:4]
#' 
#' @name scoreMarkers
NULL

#' @importFrom S4Vectors I DataFrame SimpleList
#' @importFrom DelayedArray DelayedArray
#' @importFrom BiocParallel SerialParam 
#' @importFrom Matrix t
.scoreMarkers <- function(x, groups, block=NULL, pairings=NULL, lfc=0, row.data=NULL, full.stats=FALSE, subset.row=NULL, BPPARAM=SerialParam()) {
  #    if (!is.null(design)) {
  #        if (!is.null(block)) {
  #            stop("'block' and 'design' cannot both be specified")
  #        }
  #
  #        # An unprincipled hack to deal with the design matrix for AUCs and the
  #        # logFC.detected. Especially for the latter; negative corrected values
  #        # are just set to zero and considered to be "undetected". Close enough.
  #        gdesign <- model.matrix(~0 + factor(groups))
  #        x <- ResidualMatrix::ResidualMatrix(
  #            t(DelayedArray(x)), 
  #            design=cbind(gdesign, design), 
  #            keep=seq_len(ncol(gdesign))
  #        )
  #        x <- t(x)
  #    }
  
  # Define the desired comparisons here.
  universe <- sort(unique(groups))
  desired.out <- .expand_pairings(pairings, universe=universe)
  desired.comparisons <- DataFrame(left=universe[desired.out$id1], right=universe[desired.out$id2])
  
  keep <- groups %in% desired.comparisons[,1] | groups %in% desired.comparisons[,2]

  # Preparing the data structures for processing.
  combination.out <- .group_block_combinations(groups, block)
  combination.id <- combination.out$id
  unique.combinations <- combination.out$combinations
  ncells <- tabulate(combination.id, nbins=nrow(unique.combinations))
  
  collapse.symmetric <- lfc==0
  reindexed.comparisons <- .reindex_comparisons_for_combinations(unique.combinations, desired.comparisons, collapse.symmetric=collapse.symmetric)
  left <- reindexed.comparisons$left
  right <- reindexed.comparisons$right
  
  involved <- .group_by_used_combinations(combination.id, left, right, nrow(unique.combinations))
  pre.ave <- .identify_effects_to_average(unique.combinations, reindexed.comparisons)
  desired.indices <- .cross_reference_to_desired(pre.ave$averaged.comparisons, 
                                                 desired.comparisons, 
                                                 collapse.symmetric=TRUE)
  
  # Cleaning up the rows.
  if (!is.null(row.data)) {
    if (!identical(nrow(row.data), nrow(x))) {
      stop("'row.data' and 'x' should have the same number of rows")
    }
    if (!identical(rownames(row.data), rownames(x))) {
      stop("'row.data' and 'x' should have the same row names")
    }
  }
  if (!is.null(subset.row)) {
    x <- x[subset.row,,drop=FALSE]
    row.data <- row.data[subset.row,,drop=FALSE]
  }
  
  # Performing the per-cell calculations and gathering the statistics.
  stats <- rowBlockApply(x, 
                         FUN=.compute_all_effect_sizes,
                         combination.id=combination.id, 
                         left=left, 
                         right=right, 
                         ncells=ncells,
                         unique.combinations=unique.combinations, 
                         indices.to.average=pre.ave$indices.to.average, 
                         desired.indices=desired.indices,
                         involved=involved,
                         lfc=lfc,
                         full.stats=full.stats,
                         BPPARAM=BPPARAM)
  
  res <- .mapply_bind(stats, rbind)
  
  # Slapping on the row data.
  if (!is.null(row.data)) {
    for (i in seq_along(res)) {
      res[[i]] <- cbind(row.data, res[[i]])
    }
  }
  
  SimpleList(res)
}

#####################################################################
#####################################################################

#' @importFrom S4Vectors selfmatch
.uniquify_DataFrame <- function(df) {
  id <- selfmatch(df)
  keep <- !duplicated(id)
  uid <- id[keep]
  
  # Ordering to ensure that earlier combination IDs imply earlier DF values.
  # This ensures that we can deduplicate comparisons by removing those where
  # the left ID < right ID, which implies that the left group < right group.
  # Otherwise, if the combinations were not ordered, we would have some 
  # comparisons where the left group < right group and others where the 
  # left group > right group, despite all of them having left ID < right ID;
  # this prevents collapsing of the same comparison across multiple blocks.
  ucombos <- df[keep,,drop=FALSE]
  o <- order(ucombos)
  uid <- uid[o]
  ucombos <- ucombos[o,,drop=FALSE]
  
  list(unique=ucombos, id=match(id, uid))
}

#' @importFrom S4Vectors DataFrame
.group_block_combinations <- function(groups, block) {
  everything <- DataFrame(group=groups)
  if (!is.null(block)) {
    everything$block <- block
  }
  out <- .uniquify_DataFrame(everything)
  list(combinations=out$unique, id=out$id)
}

#' @importFrom S4Vectors DataFrame
#' @importMethodsFrom S4Vectors %in%
.reindex_comparisons_for_combinations <- function(unique.combinations, desired.comparisons, collapse.symmetric=TRUE) {
  rows <- seq_len(nrow(unique.combinations))
  if (!is.null(unique.combinations$block)) {
    by.block <- split(rows, unique.combinations$block)
  } else {
    by.block <- list(rows)
  }
  
  left <- right <- block.val <- vector("list", length(by.block))
  for (i in seq_along(by.block)) {
    indices <- by.block[[i]]
    group <- unique.combinations$group[indices]
    
    # Rephrasing the desired comparisons in terms of the groups available in this block.
    mleft <- match(desired.comparisons$left, group)
    mright <- match(desired.comparisons$right, group)
    keep <- !is.na(mleft) & !is.na(mright)
    
    index.left <- indices[mleft[keep]]
    index.right <- indices[mright[keep]]
    
    if (collapse.symmetric) { 
      # Eliminating redundant comparisons with flipped orientations. This
      # is only permissible when the effect sizes are somehow symmetric.
      index.pairs <- DataFrame(left=pmax(index.left, index.right), right=pmin(index.left, index.right))
    } else {
      index.pairs <- DataFrame(left=index.left, right=index.right)
    }
    index.pairs <- unique(index.pairs)
    
    left[[i]] <- index.pairs$left
    right[[i]] <- index.pairs$right
  }
  
  DataFrame(left=unlist(left), right=unlist(right))
}

.group_by_used_combinations <- function(combination.id, left, right, ncombinations) {
  useful <- which(combination.id %in% c(left, right))
  f <- factor(combination.id[useful], seq_len(ncombinations))
  split(useful - 1L, f)
}

#####################################################################
#####################################################################

#' @importFrom scuttle summarizeAssayByGroup correctGroupSummary
.compute_all_effect_sizes <- function(x, combination.id, left, right, ncells,
                                      involved, unique.combinations, indices.to.average, desired.indices, lfc, full.stats)
{
  left.ncells <- ncells[left]
  right.ncells <- ncells[right]
  
  # Computing effects.
  stats <- compute_blocked_stats_none(x, combination.id - 1L, length(involved))
  cohen <- .compute_pairwise_cohen_d(stats[[1]], stats[[2]], left, right, lfc=lfc)
  
  detected.se <- summarizeAssayByGroup(x, combination.id, statistics=c("num.detected", "prop.detected"))
  m <- match(seq_len(nrow(unique.combinations)), detected.se$ids)
  ndetected <- assay(detected.se, withDimnames=FALSE)[,m,drop=FALSE]
  nlfc <- .compute_lfc_detected(ndetected, left, right, left.ncells, right.ncells)
  
  auc <- .compute_auc(x, involved, left, right, left.ncells, right.ncells, lfc=lfc)
  
  # Averaging across blocks and then collating.
  weights <- left.ncells * right.ncells
  output <- list(logFC.cohen=cohen, AUC=auc, logFC.detected=nlfc)
  
  for (effect in names(output)) {
    if (effect == "AUC") {
      REVERSE <- function(x) 1-x
    } else {
      REVERSE <- function(x) -x
    }
    
    ave.out <- .average_effect_across_blocks(output[[effect]], weights=weights, indices.to.average=indices.to.average)
    
    output[[effect]] <- .collate_into_DataFrame(
      desired.indices,
      averaged.effects=ave.out$averaged.effects, 
      combined.weights=ave.out$combined.weights, 
      REVERSE=REVERSE,
      effect.name=effect,
      nrow=nrow(x),
      row.names=rownames(x), 
      full.stats=full.stats) 
  }
  
  output <- .mapply_bind(output, cbind)
  
  # Computing mean stats across blocks.
  FUN <- function(...) correctGroupSummary(..., group=unique.combinations$group, block=unique.combinations$block, weights=ncells)
  more.stats <- list(
    detected=FUN(assay(detected.se, "prop.detected", withDimnames=FALSE)[,m,drop=FALSE], transform="logit"),
    average=FUN(x=stats[[1]])
  )
  
  for (i in names(more.stats)) {
    mat <- more.stats[[i]]
    for (j in names(output)) {
      existing <- output[[j]]
      self <- colnames(mat) == j
      other <- colnames(mat) %in% as.character(desired.indices[[j]]$right)
      extra <- DataFrame(self=rowMeans(mat[,self,drop=FALSE]), other=rowMeans(mat[,other,drop=FALSE]), row.names=rownames(existing))
      colnames(extra) <- paste0(colnames(extra), ".", i)
      output[[j]] <- cbind(extra, existing)
    }
  }
  
  output
}

#' @importFrom DelayedMatrixStats rowWeightedMeans
.compute_pairwise_cohen_d <- function(means, vars, left, right, lfc) {
  all.delta <- means[,left,drop=FALSE] - means[,right,drop=FALSE] - lfc
  pooled.s2 <- (vars[,left,drop=FALSE] + vars[,right,drop=FALSE])/2
  
  is.zero <- all.delta == 0
  d <- all.delta / sqrt(pooled.s2)
  d[is.zero] <- 0
  
  d
}

.compute_lfc_detected <- function(ndetected, left, right, left.ncells, right.ncells) {
  left.detected <- ndetected[,left,drop=FALSE]
  right.detected <- ndetected[,right,drop=FALSE]
  
  # Using the minimum to provide greater shrinkage when either group has very few cells.
  min.n <- pmin(left.ncells, right.ncells)
  left.pseudo <- 1 * left.ncells / min.n
  right.pseudo <- 1 * right.ncells / min.n
  
  left.prop <- (t(left.detected) + left.pseudo) / (left.ncells + left.pseudo * 2)
  right.prop <- (t(right.detected) + right.pseudo) / (right.ncells + right.pseudo * 2)
  log2(t(left.prop/right.prop))
}

.compute_auc <- function(x, involved, left, right, left.ncells, right.ncells, lfc) {
  overlap <- overlap_exprs_paired(x, left, right, involved, lfc)
  t(overlap / (left.ncells * right.ncells))
}


#####################################################################
#####################################################################

.mapply_bind <- function(df.list, FUN) {
  ref <- df.list[[1]]
  for (i in seq_along(df.list)[-1]) {
    chosen <- df.list[[i]]
    for (j in seq_along(chosen)) {
      ref[[j]] <- FUN(ref[[j]], chosen[[j]])
    }
  }
  ref
}

#' @importFrom S4Vectors DataFrame splitAsList
.identify_effects_to_average <- function(unique.combinations, reindexed.comparisons) {
  df <- DataFrame(
    left = unique.combinations$group[reindexed.comparisons$left],
    right = unique.combinations$group[reindexed.comparisons$right]
  )
  
  u.out <- .uniquify_DataFrame(df)
  comp <- u.out$unique
  
  f <- factor(u.out$id, seq_len(nrow(comp)))
  merger <- splitAsList(seq_along(f), f)
  
  list(averaged.comparisons=comp, indices.to.average=merger)
}

#' @importFrom DelayedMatrixStats rowWeightedMeans 
.average_effect_across_blocks <- function(effects, weights, indices.to.average) {
  output <- vector("list", length(indices.to.average))
  combined.weight <- numeric(length(indices.to.average))
  
  for (i in seq_along(indices.to.average)) {
    m <- indices.to.average[[i]]
    cur.e <- effects[,m,drop=FALSE]
    cur.w <- weights[m]
    combined.weight[[i]] <- sum(cur.w)
    output[[i]] <- rowWeightedMeans(cur.e, cur.w, na.rm=TRUE)
  }
  
  list(averaged.effects=output, combined.weights=combined.weight)
}

.cross_reference_to_desired <- function(averaged.comparisons, 
                                        desired.comparisons, 
                                        collapse.symmetric=TRUE) {
  averaged.comparisons = data.frame(averaged.comparisons)
  m <- match(desired.comparisons, averaged.comparisons)
  
  if (collapse.symmetric) {
    # If the symmetric comparisons were deduplicated by flipping left/right,
    # we flip them for the cross-referencing back to 'desired.comparisons'.
    flipped.comparisons <- averaged.comparisons[,2:1]
    colnames(flipped.comparisons) <- colnames(averaged.comparisons)
    fm <- match(desired.comparisons, flipped.comparisons)
  } else {
    fm <- rep(NA_integer_, nrow(desired.comparisons))
  }
  
  # drop=TRUE to ignore unused factor levels, which are highly unlikely to be desired.
  indices <- split(seq_len(nrow(desired.comparisons)), desired.comparisons$left, drop=TRUE)
  
  for (i in seq_along(indices)) {
    chosen <- indices[[i]]
    indices[[i]] <- list(
      right=desired.comparisons$right[chosen],
      direct.match=m[[1]][chosen],
      flipped.match=fm[[1]][chosen]
    )
  }
  
  indices
}

#' @importFrom S4Vectors DataFrame mcols mcols<-
#' @importFrom DelayedMatrixStats rowMins rowMedians rowMaxs 
#' @importFrom Matrix rowMeans
.collate_into_DataFrame <- function(desired.indices, averaged.effects, combined.weights, REVERSE, effect.name, nrow, row.names=NULL, full.stats=FALSE) {
  output <- desired.indices
  
  for (i in names(desired.indices)) {
    current <- desired.indices[[i]]
    
    right <- current$right
    collated <- vector("list", length(right))
    names(collated) <- right
    w <- numeric(length(right))
    
    original <- current$direct.match
    keep <- !is.na(original)
    if (any(keep)) {
      original.kept <- original[keep]
      collated[keep] <- averaged.effects[original.kept]
      w[keep] <- combined.weights[original.kept]
    }
    
    flipped <- current$flipped.match
    fkeep <- !is.na(flipped)
    if (any(fkeep)) {
      flipped.kept <- flipped[fkeep]
      collated[fkeep] <- lapply(averaged.effects[flipped.kept], REVERSE)
      w[fkeep] <- combined.weights[flipped.kept]
    }
    
    # Filling in the leftovers, e.g., due to an impossible comparison.
    for (j in which(!keep & !fkeep)) {
      collated[[j]] <- rep(NA_real_, nrow)
    }
    
    # 'current', and thus 'collated', is guaranteed to be non-empty due to drop=TRUE.
    # As such, there's no need to implement any protection in the constructor.
    full <- DataFrame(collated, row.names=row.names, check.names=FALSE)
    
    effect.mat <- as.matrix(full)
    df <- DataFrame(
      mean=rowMeans(effect.mat, na.rm=TRUE),
      min=rowMins(effect.mat, na.rm=TRUE),
      median=rowMedians(effect.mat, na.rm=TRUE),
      max=rowMaxs(effect.mat, na.rm=TRUE),
      rank=computeMinRank(effect.mat),
      row.names=row.names
    )
    
    if (full.stats) {
      mcols(full)$weight <- w
      df$full <- full
    }
    
    colnames(df) <- paste0(colnames(df), ".", effect.name)
    
    output[[i]] <- df
  }
  
  output
}

#####################################################################
#####################################################################

#' @export
#' @rdname scoreMarkers
setGeneric("scoreMarkers", function(x, ...) standardGeneric("scoreMarkers"))

#' @export
#' @rdname scoreMarkers
setMethod("scoreMarkers", "ANY", .scoreMarkers) 

#' @export
#' @rdname scoreMarkers
#' @importFrom SummarizedExperiment assay
setMethod("scoreMarkers", "SummarizedExperiment", function(x, groups, ..., assay.type="logcounts") {
  .scoreMarkers(assay(x, assay.type), groups, ...)
})

#' @export
#' @rdname scoreMarkers
#' @importFrom SingleCellExperiment colLabels
setMethod("scoreMarkers", "SingleCellExperiment", function(x, groups=colLabels(x, onAbsence="error"), ...) {
  callNextMethod(x, groups=groups, ...)
})


compute_blocked_stats_none <- function(mat, block, nblocks) {
  .Call('_scran_compute_blocked_stats_none', PACKAGE = 'scran', mat, block, nblocks)
}

compute_Top_statistic_from_ranks <- function(Ranks, prop) {
  .Call('_scran_compute_Top_statistic_from_ranks', PACKAGE = 'scran', Ranks, prop)
}

choose_middle_effect_size <- function(Pvals, Effects, prop) {
  .Call('_scran_choose_middle_effect_size', PACKAGE = 'scran', Pvals, Effects, prop)
}

combine_rho <- function(Ngenes, first, second, Rho, Pval, Order) {
  .Call('_scran_combine_rho', PACKAGE = 'scran', Ngenes, first, second, Rho, Pval, Order)
}

compute_blocked_stats_lognorm <- function(mat, block, nblocks, sf, pseudo) {
  .Call('_scran_compute_blocked_stats_lognorm', PACKAGE = 'scran', mat, block, nblocks, sf, pseudo)
}

compute_blocked_stats_norm <- function(mat, block, nblocks, sf) {
  .Call('_scran_compute_blocked_stats_norm', PACKAGE = 'scran', mat, block, nblocks, sf)
}

compute_blocked_stats_none <- function(mat, block, nblocks) {
  .Call('_scran_compute_blocked_stats_none', PACKAGE = 'scran', mat, block, nblocks)
}

compute_residual_stats_lognorm <- function(qr, qraux, inmat, sf, pseudo) {
  .Call('_scran_compute_residual_stats_lognorm', PACKAGE = 'scran', qr, qraux, inmat, sf, pseudo)
}

compute_residual_stats_none <- function(qr, qraux, inmat) {
  .Call('_scran_compute_residual_stats_none', PACKAGE = 'scran', qr, qraux, inmat)
}

get_null_rho <- function(Ncells, Niters, Seeds, Streams) {
  .Call('_scran_get_null_rho', PACKAGE = 'scran', Ncells, Niters, Seeds, Streams)
}

get_null_rho_design <- function(qr, qraux, Niters, Seeds, Streams) {
  .Call('_scran_get_null_rho_design', PACKAGE = 'scran', qr, qraux, Niters, Seeds, Streams)
}

cyclone_scores <- function(exprs, marker1, marker2, indices, niters, miniters, minpairs, seeds, streams) {
  .Call('_scran_cyclone_scores', PACKAGE = 'scran', exprs, marker1, marker2, indices, niters, miniters, minpairs, seeds, streams)
}

overlap_exprs <- function(exprs, groups, lfc) {
  .Call('_scran_overlap_exprs', PACKAGE = 'scran', exprs, groups, lfc)
}

overlap_exprs_paired <- function(exprs, left, right, groups, lfc) {
  .Call('_scran_overlap_exprs_paired', PACKAGE = 'scran', exprs, left, right, groups, lfc)
}


.expand_pairings <- function(pairings, universe) {
  .SUBSET <- function(request, clean=TRUE) {
    if (is.null(request)) {
      out <- seq_along(universe)
    } else { 
      out <- match(request, universe)
    }
    if (clean) {
      out <- unique(out[!is.na(out)])
    }
    out
  }
  
  .expand_pairings_core(pairings, .SUBSET)
}

.expand_pairings_core <- function(pairings, .SUBSET) {
  .clean_expand <- function(x, y, keep.perm) {
    all.pairs <- expand.grid(x, y)
    keep <- all.pairs[,1] != all.pairs[,2]
    all.pairs[keep,]
  }
  
  if (is.matrix(pairings)) {
    # If matrix, we're using pre-specified pairs.
    if ((!is.numeric(pairings) && !is.character(pairings)) || ncol(pairings)!=2L) {
      stop("'pairings' should be a numeric/character matrix with 2 columns")
    }
    s1 <- .SUBSET(pairings[,1], clean=FALSE)
    s2 <- .SUBSET(pairings[,2], clean=FALSE)
    
    # Discarding pairs with missing elements silently.
    keep <- !is.na(s1) & !is.na(s2)
    s1 <- s1[keep]
    s2 <- s2[keep]
    mode <- "predefined pairs"
    
  } else if (is.list(pairings)) {
    # If list, we're correlating between one gene selected from each of two pools.
    if (length(pairings)!=2L) {
      stop("'pairings' as a list should have length 2")
    }
    converted <- lapply(pairings, FUN=.SUBSET)
    all.pairs <- .clean_expand(converted[[1]], converted[[2]])
    s1 <- all.pairs[,1]
    s2 <- all.pairs[,2]
    mode <- "double pool"
    
  } else {
    available <- .SUBSET(pairings)
    all.pairs <- .clean_expand(available, available)
    s1 <- all.pairs[,1]
    s2 <- all.pairs[,2]
    mode <- "single pool"
  }
  
  list(id1=s1, id2=s2, mode=mode)
}
```

merge.scref.R
```{r, eval = FALSE}
data.d0.a = readRDS("rds/sc.uIRI.d0.raw.RDS")
data.d1.a = readRDS("rds/sc.uIRI.d1.raw.RDS")
data.d2.a = readRDS("rds/sc.uIRI.d2.raw.RDS")
scUIRI.combined = merge(data.d0.a, y = c(data.d1.a, data.d2.a), 
                        add.cell.ids = c("Ctrl", "d1", "d2"), 
                        project = "GSE139506")

scpark = readRDS("rds/park.seurat.raw.RDS")
scpark$Idents = scpark$cell.type

sc.merged = merge(data.d0.a, y = c(data.d1.a, data.d2.a, scpark), 
                  add.cell.ids = c("Ctrl", "d1", "d2", "park"), 
                  project = "GSE139506+GSE10758")
# saveRDS(sc.merged, "rds/park.uniIRI.merged.raw.RDS")

sc.merged = SplitObject(sc.merged, split.by = "orig.ident")
sc.merged = lapply(X = sc.merged, FUN = SCTransform)
features = SelectIntegrationFeatures(object.list = sc.merged, nfeatures = 3000)
sc.merged = PrepSCTIntegration(object.list = sc.merged, anchor.features = features)
scanchors = FindIntegrationAnchors(object.list = sc.merged, 
                                   normalization.method = "SCT",
                                   anchor.features = features)
sc.merged.sct = IntegrateData(anchorset = scanchors, normalization.method = "SCT")
# saveRDS(sc.merged.sct, "rds/park.uniIRI.merged.sct.raw.RDS")

sc.merged.sct = RunPCA(sc.merged.sct, verbose = FALSE)
sc.merged.sct = RunTSNE(sc.merged.sct, verbose = FALSE)
sc.merged.sct = RunUMAP(sc.merged.sct, reduction = "pca", dims = 1:20)
# saveRDS(sc.merged.sct, "rds/park.uniIRI.merged.sct.ok.RDS")

DimPlot(sc.merged.sct, reduction = "umap", group.by = "Idents", label = TRUE)
DimPlot(sc.merged.sct, reduction = "umap", label = TRUE, group.by = "orig.ident") 
DimPlot(sc.merged.sct, reduction = "pca", label = TRUE, group.by = "orig.ident") 

gc()

sc.IRI = readRDS("rds/sc.uIRI.combined.ok.RDS")
sc.SCT = readRDS("rds/park.uniIRI.merged.sct.ok.RDS")

sc.unSCT = readRDS("rds/park.uniIRI.merged.raw.RDS")
sc.unSCT = FindVariableFeatures(sc.unSCT)
sc.unSCT = SCTransform(sc.unSCT)
sc.unSCT = RunPCA(sc.unSCT, verbose = FALSE)
sc.unSCT = RunTSNE(sc.unSCT, verbose = FALSE)
sc.unSCT = RunUMAP(sc.unSCT, reduction = "pca", dims = 1:20)
DimPlot(sc.unSCT, reduction = "umap", label = TRUE, group.by = "orig.ident") 
DimPlot(sc.unSCT, reduction = "pca", label = TRUE, group.by = "orig.ident") 

p1 = DimPlot(sc.unSCT, reduction = "umap", label = TRUE, group.by = "orig.ident") + ggtitle("Pre-integration")
p2 = DimPlot(sc.SCT, reduction = "umap", label = TRUE, group.by = "orig.ident")  + ggtitle("Post-integration")

tiff("figures/scref.pre.post.integration.tiff", res = 300, units = "cm", height = 20, width = 40)
p1 - p2
dev.off()

DimPlot(sc.SCT, reduction = "umap", label = TRUE, group.by = "Idents", split.by = "orig.ident") + ggtitle("Integrated scREFs")
DimPlot(sc.IRI, reduction = "umap", label = TRUE, group.by = "Idents", split.by = "orig.ident") + ggtitle("Integrated scREFs")
DimPlot(sc.IRI, reduction = "umap", label = TRUE,  repel = TRUE, group.by= "Idents") + ggtitle("Integrated scREFs")

tiff("figures/scref.integration.cells.tiff", res = 300, units = "cm", height = 15, width = 22)
DimPlot(sc.IRI, reduction = "umap", label = TRUE,  repel = TRUE, group.by= "Idents") + ggtitle("Integrated scREFs")
dev.off()
```

GSE10758 Parkraw.R
```{r, eval = FALSE}
############################################################
############ Park/Sustak, Science, 2018 ####################
############################################################
library(GEOquery)
gse1 = read.delim((gzfile('scref/GSE107585/GSE107585_Mouse_kidney_single_cell_datamatrix.txt.gz')))

# separate the matrix into components
meta.park = gse1[1,]
meta.park = data.frame(t(meta.park))
meta.park = meta.park %>% mutate(cell.type = case_when(
  Cluster_Number == 1 ~ "Endo", Cluster_Number == 2 ~ "Podo",
  Cluster_Number == 3 ~ "PT", Cluster_Number == 4 ~ "LOH",
  Cluster_Number == 5 ~ "DCT", Cluster_Number == 6 ~ "CD-PC",
  Cluster_Number == 7 ~ "CD-IC", Cluster_Number == 8 ~ "CD-T",
  Cluster_Number == 9 ~ "Novel1",  Cluster_Number == 10 ~ "Fib",
  Cluster_Number == 11 ~ "Macro",  Cluster_Number == 12 ~ "Neutro",
  Cluster_Number == 13 ~ "B Lymph", Cluster_Number == 14 ~ "T Lymph",
  Cluster_Number == 15 ~ "NK", Cluster_Number == 16 ~ "Novel2"))
gse.a = gse1[-1,]
head(gse.a)

saveRDS(gse.a, "rds/park.raw.RDS")
saveRDS(meta.park, "rds/park.meta.data.RDS")

# Make into  seurat object
park = CreateSeuratObject(counts = gse.a,
                          meta.data = meta.park,
                          project = "GSE107585",
                          min.cells = 20, 
                          min.features = 200)

saveRDS(park, "rds/park.seurat.raw.RDS")

###

# Seurat processing from raw data
sc.park.seurat = SCTransform(park, 
                             assay = 'RNA', 
                             conserve.memory = TRUE)
sc.park.seurat$Cluster_Number = as.factor(sc.park.seurat$Cluster_Number)
sc.park.seurat = RunPCA(sc.park.seurat)
sc.park.seurat = RunTSNE(sc.park.seurat)

# sc.park.seurat = RunUMAP(sc.park.seurat)
DimPlot(sc.park.seurat, reduction = "tsne", group = "cell.type")

sc.park.seurat$cellType = sc.park.seurat$Cluster_Number
levels(sc.park.seurat$cellType) = c("Endothelial", "Podo", "Prox.tubules",
                                    "Loop", "DCT", "CD.PC", "CD.IC", "CD.Tran", 
                                    "Novel1", "Novel2", "Fib", "Macro", "Neutro", 
                                    "B.lymph", "T.lymph", "NK", "Novel2")
DimPlot(sc.park.seurat, reduction = "tsne", group = "cellType")

saveRDS(sc.park.seurat, "rds/sc.park.seurat.ok.RDS")

#########################################
# Make into SingleCellExperiment version
sce = SingleCellExperiment(list(counts=gse.a))
libsizes = colSums(gse.a)
size.factors = libsizes/mean(libsizes)
logcounts(sce) = log2(t(t(gse.a)/size.factors) + 1)
assayNames(sce)
saveRDS(sce, "rds/park.sce.raw.RDS")

```

gse138506raw.R
```{r, eval = FALSE}
### GSE 139506 
meta.control = read.delim("scref/GSE139506/CONTROL_IRI_metadata_table.txt")
meta.d1 = read.delim("scref/GSE139506/DAY1_IRI_metadata_table.txt")
meta.d2 = read.delim("scref/GSE139506/DAY2_IRI_metadata_table.txt")
data.d0.a0 = read.delim(gzfile("scref/GSE139506/GSM4142623_CONTROL_dge.txt.gz"))
data.d1.a0 = read.delim(gzfile("scref/GSE139506/GSM4142624_DAY1_dge.txt.gz"))
data.d2.a0 = read.delim(gzfile("scref/GSE139506/GSM4142625_DAY2_dge.txt.gz"))
gc()

# day 0
data.d0.a = data.d0.a0
remove1 = data.d0.a$GENE[grep("_", data.d0.a$GENE)]
data.d0.a = data.d0.a[!(data.d0.a$GENE %in% remove1),]
rownames(data.d0.a) = data.d0.a$GENE
data.d0.a = data.d0.a[,-1] # remove GENE row (now rowname)
data.d0.a = data.d0.a[,colnames(data.d0.a) %in% meta.control$X]
# filtering already done by their meta data coverage

data.d0.a = CreateSeuratObject(counts = data.d0.a,
                               assay = "RNA",
                               project = "GSE139506.control")

data.d0.a@meta.data$percent.mt =  meta.control$percent.mt
data.d0.a@meta.data$seurat_clusters =  meta.control$seurat_clusters
data.d0.a@meta.data$Idents =  meta.control$Idents
data.d0.a@meta.data$UMAP_1 =  meta.control$UMAP_1
data.d0.a@meta.data$UMAP_2 =  meta.control$UMAP_2

saveRDS(data.d0.a, "rds/sc.uIRI.d0.raw.RDS")
# data.d0.a = readRDS("rds/sc.uIRI.d0.raw.RDS")


# day 1
data.d1.a = data.d1.a0
remove1 = data.d1.a$GENE[grep("_", data.d1.a$GENE)]
data.d1.a = data.d1.a[!(data.d1.a$GENE %in% remove1),]
rownames(data.d1.a) = data.d1.a$GENE
data.d1.a = data.d1.a[,-1] # remove GENE row (now rowname)
data.d1.a = data.d1.a[,colnames(data.d1.a) %in% meta.d1$X]

data.d1.a = CreateSeuratObject(counts = data.d1.a,
                               assay = "RNA",
                               project = "GSE139506.d1")

data.d1.a@meta.data$percent.mt =  meta.d1$percent.mt
data.d1.a@meta.data$seurat_clusters =  meta.d1$seurat_clusters
data.d1.a@meta.data$Idents =  meta.d1$Idents
data.d1.a@meta.data$UMAP_1 =  meta.d1$UMAP_1
data.d1.a@meta.data$UMAP_2 =  meta.d1$UMAP_2

saveRDS(data.d1.a, "rds/sc.uIRI.d1.raw.RDS")

# day 2
data.d2.a = data.d2.a0
remove1 = data.d2.a$GENE[grep("_", data.d2.a$GENE)]
data.d2.a = data.d2.a[!(data.d2.a$GENE %in% remove1),]
rownames(data.d2.a) = data.d2.a$GENE
data.d2.a = data.d2.a[,-1] # remove GENE row (now rowname)
data.d2.a = data.d2.a[,colnames(data.d2.a) %in% meta.d2$X]

data.d2.a = CreateSeuratObject(counts = data.d2.a,
                               assay = "RNA",
                               project = "GSE139506.d2")

data.d2.a@meta.data$percent.mt =  meta.d2$percent.mt
data.d2.a@meta.data$seurat_clusters =  meta.d2$seurat_clusters
data.d2.a@meta.data$Idents =  meta.d2$Idents
data.d2.a@meta.data$UMAP_1 =  meta.d2$UMAP_1
data.d2.a@meta.data$UMAP_2 =  meta.d2$UMAP_2

saveRDS(data.d2.a, "rds/sc.uIRI.d2.raw.RDS")

# Data integration
scUIRI.combined <- merge(data.d0.a, y = c(data.d1.a, data.d2.a), 
                         add.cell.ids = c("Ctrl", "d1", "d2"), 
                         project = "GSE139506")

scuiri.list = SplitObject(scUIRI.combined, split.by = "orig.ident")
scuiri.list = lapply(X = scuiri.list, FUN = SCTransform)
features = SelectIntegrationFeatures(object.list = scuiri.list, nfeatures = 3000)
scuiri.list = PrepSCTIntegration(object.list = scuiri.list, anchor.features = features)
scanchors = FindIntegrationAnchors(object.list = scuiri.list, 
                                   normalization.method = "SCT",
                                   anchor.features = features)
scanchors.sct = IntegrateData(anchorset = scanchors, 
                              normalization.method = "SCT")
scanchors.sct = RunPCA(scanchors.sct, verbose = FALSE)
scanchors.sct = RunTSNE(scanchors.sct, verbose = FALSE)
scanchors.sct = RunUMAP(scanchors.sct, reduction = "pca", dims = 1:20)

DimPlot(scanchors.sct, reduction = "umap", group.by = "Idents", label = TRUE)
DimPlot(scanchors.sct, reduction = "umap", label = TRUE, split.by = "orig.ident") 

saveRDS(scanchors.sct, "rds/sc.uIRI.combined.ok.RDS")

# Individual sets processed
data.d0.a = SCTransform(data.d0.a, assay = 'RNA', conserve.memory = TRUE)
data.d0.a = RunPCA(data.d0.a)
data.d0.a = RunTSNE(data.d0.a)
data.d0.a = RunUMAP(data.d0.a, reduction = "pca", dims = 1:20)
DimPlot(data.d0.a, reduction = "umap", group.by = "Idents", label = TRUE)

saveRDS(data.d0.a, "rds/sc.uIRI.d0.RDS")
gc()

data.d1.a = SCTransform(data.d1.a, assay = 'RNA', conserve.memory = TRUE)
data.d1.a = RunPCA(data.d1.a)
data.d1.a = RunTSNE(data.d1.a)
data.d1.a = RunUMAP(data.d1.a,  reduction = "pca", dims = 1:20)
DimPlot(data.d1.a, reduction = "umap", group.by = "Idents", label = TRUE)

saveRDS(data.d1.a, "rds/sc.uIRI.d1.RDS")
gc()

data.d2.a = SCTransform(data.d2.a, assay = 'RNA', conserve.memory = TRUE)
data.d2.a = RunPCA(data.d2.a)
data.d2.a = RunTSNE(data.d2.a)
data.d2.a = RunUMAP(data.d2.a, reduction = "pca",  dims = 1:20)
DimPlot(data.d2.a, reduction = "umap",  group.by = "Idents", label = TRUE)

saveRDS(data.d2.a, "rds/sc.uIRI.d2.RDS")
gc()
```
